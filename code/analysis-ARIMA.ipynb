{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sdt.changepoint as c\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ARIMA libraries\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.graphics import tsaplots\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pmdarima as pm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from the csv file\n",
    "df_new_cases = pd.read_csv('../data/WHO-COVID-19-global-data.csv')\n",
    "#df_vaccination = pd.read_csv('../data/owid-covid-data.csv')\n",
    "df_vaccination = pd.read_csv('../data/country_vaccinations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add moving average for new cases\n",
    "#df_vaccination['moving_average_new_vaccinations'] = df_vaccination.groupby('iso_code')['new_vaccinations'].transform(lambda x: x.rolling(window=7).mean()) # OWID\n",
    "df_vaccination['moving_average_new_vaccinations'] = df_vaccination.groupby('iso_code')['daily_vaccinations'].transform(lambda x: x.rolling(window=7).mean())\n",
    "\n",
    "# rimuovi tutte le righe che non hanno un valore o hanno un valore a \"0.0\" per moving_average_new_cases\n",
    "df_vaccination = df_vaccination.dropna(subset=['moving_average_new_vaccinations'])\n",
    "df_vaccination = df_vaccination[df_vaccination['moving_average_new_vaccinations'] != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add moving average for new cases\n",
    "df_new_cases['moving_average_new_cases'] = df_new_cases.groupby('Country_code')['New_cases'].transform(lambda x: x.rolling(window=7).mean())\n",
    "\n",
    "# rimuovi tutte le righe che non hanno un valore o hanno un valore a \"0.0\" per moving_average_new_cases\n",
    "df_new_cases = df_new_cases.dropna(subset=['moving_average_new_cases'])\n",
    "df_new_cases = df_new_cases[df_new_cases['moving_average_new_cases'] != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firter data from 2021-07-16 to 2021-08-15\n",
    "start_date = date(2021, 1, 1) \n",
    "og_start_date = date(2021, 7, 22)\n",
    "og_end_date = date(2021, 8, 9)\n",
    "end_date = date(2021, 8, 31)\n",
    "\n",
    "difference = og_start_date - start_date\n",
    "event_duration = og_end_date - og_start_date\n",
    "\n",
    "# filter df_vaccination and df_new_cases from 2020-12-08 to 2021-08-31\n",
    "start_vaccination = date(2020, 12, 8)\n",
    "end_study = date(2021, 8, 31)\n",
    "df_vaccination = df_vaccination[(df_vaccination['date'] >= str(start_vaccination)) & (df_vaccination['date'] <= str(end_study))]\n",
    "df_vaccination = df_vaccination.reset_index(drop=True)\n",
    "df_new_cases = df_new_cases[(df_new_cases['Date_reported'] >= str(start_vaccination)) & (df_new_cases['Date_reported'] <= str(end_study))]\n",
    "df_new_cases = df_new_cases.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter by iso_cod that not contain \"OWID\" prefix\n",
    "df_vaccination = df_vaccination[~df_vaccination['iso_code'].str.contains(\"OWID\")]\n",
    "\n",
    "# aggragate by iso_code and date and sum total_cases, total_deaths, population, total_vaccinations, new_cases, mind positive_rate, max positive_rate,KEEP LOCATION \n",
    "#df_vaccination = df_vaccination.groupby(['iso_code', 'date']).agg({'people_vaccinated':'sum', 'new_vaccinations': 'sum', 'location': 'max', 'moving_average_new_vaccinations': 'sum'})\n",
    "df_vaccination = df_vaccination.groupby(['iso_code', 'date']).agg({'total_vaccinations':'sum', 'daily_vaccinations': 'sum', 'country': 'max', 'moving_average_new_vaccinations': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggiungi alla riga attuale nella colonna iso_code il valore iso\n",
    "convert_ISO_3166_2_to_1 = {\n",
    "    'AF':'AFG',\n",
    "    'AX':'ALA',\n",
    "    'AL':'ALB',\n",
    "    'DZ':'DZA',\n",
    "    'AS':'ASM',\n",
    "    'AD':'AND',\n",
    "    'AO':'AGO',\n",
    "    'AI':'AIA',\n",
    "    'AQ':'ATA',\n",
    "    'AG':'ATG',\n",
    "    'AR':'ARG',\n",
    "    'AM':'ARM',\n",
    "    'AW':'ABW',\n",
    "    'AU':'AUS',\n",
    "    'AT':'AUT',\n",
    "    'AZ':'AZE',\n",
    "    'BS':'BHS',\n",
    "    'BH':'BHR',\n",
    "    'BD':'BGD',\n",
    "    'BB':'BRB',\n",
    "    'BY':'BLR',\n",
    "    'BE':'BEL',\n",
    "    'BZ':'BLZ',\n",
    "    'BJ':'BEN',\n",
    "    'BM':'BMU',\n",
    "    'BT':'BTN',\n",
    "    'BO':'BOL',\n",
    "    'BA':'BIH',\n",
    "    'BW':'BWA',\n",
    "    'BV':'BVT',\n",
    "    'BR':'BRA',\n",
    "    'IO':'IOT',\n",
    "    'BN':'BRN',\n",
    "    'BG':'BGR',\n",
    "    'BF':'BFA',\n",
    "    'BI':'BDI',\n",
    "    'KH':'KHM',\n",
    "    'CM':'CMR',\n",
    "    'CA':'CAN',\n",
    "    'CV':'CPV',\n",
    "    'KY':'CYM',\n",
    "    'CF':'CAF',\n",
    "    'TD':'TCD',\n",
    "    'CL':'CHL',\n",
    "    'CN':'CHN',\n",
    "    'CX':'CXR',\n",
    "    'CC':'CCK',\n",
    "    'CO':'COL',\n",
    "    'KM':'COM',\n",
    "    'CG':'COG',\n",
    "    'CD':'COD',\n",
    "    'CK':'COK',\n",
    "    'CR':'CRI',\n",
    "    'CI':'CIV',\n",
    "    'HR':'HRV',\n",
    "    'CU':'CUB',\n",
    "    'CY':'CYP',\n",
    "    'CZ':'CZE',\n",
    "    'DK':'DNK',\n",
    "    'DJ':'DJI',\n",
    "    'DM':'DMA',\n",
    "    'DO':'DOM',\n",
    "    'EC':'ECU',\n",
    "    'EG':'EGY',\n",
    "    'SV':'SLV',\n",
    "    'GQ':'GNQ',\n",
    "    'ER':'ERI',\n",
    "    'EE':'EST',\n",
    "    'ET':'ETH',\n",
    "    'FK':'FLK',\n",
    "    'FO':'FRO',\n",
    "    'FJ':'FJI',\n",
    "    'FI':'FIN',\n",
    "    'FR':'FRA',\n",
    "    'GF':'GUF',\n",
    "    'PF':'PYF',\n",
    "    'TF':'ATF',\n",
    "    'GA':'GAB',\n",
    "    'GM':'GMB',\n",
    "    'GE':'GEO',\n",
    "    'DE':'DEU',\n",
    "    'GH':'GHA',\n",
    "    'GI':'GIB',\n",
    "    'GR':'GRC',\n",
    "    'GL':'GRL',\n",
    "    'GD':'GRD',\n",
    "    'GP':'GLP',\n",
    "    'GU':'GUM',\n",
    "    'GT':'GTM',\n",
    "    'GG':'GGY',\n",
    "    'GN':'GIN',\n",
    "    'GW':'GNB',\n",
    "    'GY':'GUY',\n",
    "    'HT':'HTI',\n",
    "    'HM':'HMD',\n",
    "    'VA':'VAT',\n",
    "    'HN':'HND',\n",
    "    'HK':'HKG',\n",
    "    'HU':'HUN',\n",
    "    'IS':'ISL',\n",
    "    'IN':'IND',\n",
    "    'ID':'IDN',\n",
    "    'IR':'IRN',\n",
    "    'IQ':'IRQ',\n",
    "    'IE':'IRL',\n",
    "    'IM':'IMN',\n",
    "    'IL':'ISR',\n",
    "    'IT':'ITA',\n",
    "    'JM':'JAM',\n",
    "    'JP':'JPN',\n",
    "    'JE':'JEY',\n",
    "    'JO':'JOR',\n",
    "    'KZ':'KAZ',\n",
    "    'KE':'KEN',\n",
    "    'KI':'KIR',\n",
    "    'KP':'PRK',\n",
    "    'KR':'KOR',\n",
    "    'KW':'KWT',\n",
    "    'KG':'KGZ',\n",
    "    'LA':'LAO',\n",
    "    'LV':'LVA',\n",
    "    'LB':'LBN',\n",
    "    'LS':'LSO',\n",
    "    'LR':'LBR',\n",
    "    'LY':'LBY',\n",
    "    'LI':'LIE',\n",
    "    'LT':'LTU',\n",
    "    'LU':'LUX',\n",
    "    'MO':'MAC',\n",
    "    'MK':'MKD',\n",
    "    'MG':'MDG',\n",
    "    'MW':'MWI',\n",
    "    'MY':'MYS',\n",
    "    'MV':'MDV',\n",
    "    'ML':'MLI',\n",
    "    'MT':'MLT',\n",
    "    'MH':'MHL',\n",
    "    'MQ':'MTQ',\n",
    "    'MR':'MRT',\n",
    "    'MU':'MUS',\n",
    "    'YT':'MYT',\n",
    "    'MX':'MEX',\n",
    "    'FM':'FSM',\n",
    "    'MD':'MDA',\n",
    "    'MC':'MCO',\n",
    "    'MN':'MNG',\n",
    "    'ME':'MNE',\n",
    "    'MS':'MSR',\n",
    "    'MA':'MAR',\n",
    "    'MZ':'MOZ',\n",
    "    'MM':'MMR',\n",
    "    'NA':'NAM',\n",
    "    'NR':'NRU',\n",
    "    'NP':'NPL',\n",
    "    'NL':'NLD',\n",
    "    'AN':'ANT',\n",
    "    'NC':'NCL',\n",
    "    'NZ':'NZL',\n",
    "    'NI':'NIC',\n",
    "    'NE':'NER',\n",
    "    'NG':'NGA',\n",
    "    'NU':'NIU',\n",
    "    'NF':'NFK',\n",
    "    'MP':'MNP',\n",
    "    'NO':'NOR',\n",
    "    'OM':'OMN',\n",
    "    'PK':'PAK',\n",
    "    'PW':'PLW',\n",
    "    'PS':'PSE',\n",
    "    'PA':'PAN',\n",
    "    'PG':'PNG',\n",
    "    'PY':'PRY',\n",
    "    'PE':'PER',\n",
    "    'PH':'PHL',\n",
    "    'PN':'PCN',\n",
    "    'PL':'POL',\n",
    "    'PT':'PRT',\n",
    "    'PR':'PRI',\n",
    "    'QA':'QAT',\n",
    "    'RE':'REU',\n",
    "    'RO':'ROU',\n",
    "    'RU':'RUS',\n",
    "    'RW':'RWA',\n",
    "    'BL':'BLM',\n",
    "    'SH':'SHN',\n",
    "    'KN':'KNA',\n",
    "    'LC':'LCA',\n",
    "    'MF':'MAF',\n",
    "    'PM':'SPM',\n",
    "    'VC':'VCT',\n",
    "    'WS':'WSM',\n",
    "    'SM':'SMR',\n",
    "    'ST':'STP',\n",
    "    'SA':'SAU',\n",
    "    'SN':'SEN',\n",
    "    'RS':'SRB',\n",
    "    'SC':'SYC',\n",
    "    'SL':'SLE',\n",
    "    'SG':'SGP',\n",
    "    'SK':'SVK',\n",
    "    'SI':'SVN',\n",
    "    'SB':'SLB',\n",
    "    'SO':'SOM',\n",
    "    'ZA':'ZAF',\n",
    "    'GS':'SGS',\n",
    "    'ES':'ESP',\n",
    "    'LK':'LKA',\n",
    "    'SD':'SDN',\n",
    "    'SR':'SUR',\n",
    "    'SJ':'SJM',\n",
    "    'SZ':'SWZ',\n",
    "    'SE':'SWE',\n",
    "    'CH':'CHE',\n",
    "    'SY':'SYR',\n",
    "    'TW':'TWN',\n",
    "    'TJ':'TJK',\n",
    "    'TZ':'TZA',\n",
    "    'TH':'THA',\n",
    "    'TL':'TLS',\n",
    "    'TG':'TGO',\n",
    "    'TK':'TKL',\n",
    "    'TO':'TON',\n",
    "    'TT':'TTO',\n",
    "    'TN':'TUN',\n",
    "    'TR':'TUR',\n",
    "    'TM':'TKM',\n",
    "    'TC':'TCA',\n",
    "    'TV':'TUV',\n",
    "    'UG':'UGA',\n",
    "    'UA':'UKR',\n",
    "    'AE':'ARE',\n",
    "    'GB':'GBR',\n",
    "    'US':'USA',\n",
    "    'UM':'UMI',\n",
    "    'UY':'URY',\n",
    "    'UZ':'UZB',\n",
    "    'VU':'VUT',\n",
    "    'VE':'VEN',\n",
    "    'VN':'VNM',\n",
    "    'VG':'VGB',\n",
    "    'VI':'VIR',\n",
    "    'WF':'WLF',\n",
    "    'EH':'ESH',\n",
    "    'YE':'YEM',\n",
    "    'ZM':'ZMB',\n",
    "    'ZW':'ZWE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set country_code like index\n",
    "df_new_cases = df_new_cases.set_index('Country_code')\n",
    "country_list = df_new_cases.index.get_level_values('Country_code').unique()\n",
    "\n",
    "for code in country_list:\n",
    "    if code not in convert_ISO_3166_2_to_1:\n",
    "        #print(code , \"NOT FOUND\")\n",
    "        continue\n",
    "    iso = convert_ISO_3166_2_to_1[code]\n",
    "    df_new_cases.loc[(df_new_cases.index.get_level_values('Country_code') == code), 'iso_code'] = iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns of date_reported\n",
    "df_new_cases.rename(columns={'Date_reported':'date'}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggragate by iso_code and date and sum total_cases, total_deaths, population, total_vaccinations, new_cases, mind positive_rate, max positive_rate,KEEP LOCATION \n",
    "df_new_cases = df_new_cases.groupby(['iso_code', 'date']).agg({'Country': 'sum', 'New_cases': 'sum', 'moving_average_new_cases': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe in csv file\n",
    "df_new_cases.to_csv('./out/ARIMA/ARIMA_dataframe.csv')\n",
    "df_vaccination.to_csv('./out/ARIMA/ARIMA_vaccinations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for iso_code in df_vaccination.index.get_level_values('iso_code').unique():\n",
    "    plt.plot(df_vaccination.loc[iso_code]['moving_average_new_vaccinations'], label='vaccinations')\n",
    "    plt.title(df_vaccination.loc[iso_code]['country'].unique()[0])\n",
    "    plt.ylabel(\"new vaccinations\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# crea una lista di tutti gli iso_code presenti in df_new_cases\n",
    "iso_code_list = df_new_cases.index.get_level_values('iso_code').unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df_train, df_test):\n",
    "    min_rmse = 10000000\n",
    "    best_model = None\n",
    "    best_d = 0\n",
    "    best_pred = None\n",
    "    for diff in range(0, 3):\n",
    "        model = pm.auto_arima(df_train[\"moving_average_new_cases\"], X=df_train[[\"moving_average_new_vaccinations\"]], start_p=0, start_q=0,\n",
    "                              # usiamo il test adf per la stazionarietà.\n",
    "                              test='adf',\n",
    "                              max_p=5, max_q=5,\n",
    "                              d=diff,  # ordine della prima differenziazione\n",
    "                              error_action='ignore', trace=True,\n",
    "                              suppress_warnings=True,\n",
    "                              random_state=42,\n",
    "                              stagionality=True,\n",
    "                              maxiter=500, m=4, stationary=False)\n",
    "\n",
    "        pred, ci = model.predict(n_periods=len(\n",
    "            df_test[\"moving_average_new_cases\"]), X=df_test[[\"moving_average_new_vaccinations\"]], alpha=0.05, return_conf_int=True)\n",
    "\n",
    "        rmse = math.sqrt(mean_squared_error(\n",
    "            df_test[\"moving_average_new_cases\"], pred))\n",
    "        # print('Test RMSE: %.3f' % rmse)\n",
    "        if rmse < min_rmse:\n",
    "            min_rmse = rmse\n",
    "            best_model = model\n",
    "            best_pred = pred\n",
    "            best_d = diff\n",
    "    return best_model, best_pred, best_d, min_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabella = pd.DataFrame(columns=['State','Full','Before','During','After'])\n",
    "trend_negative = []\n",
    "trend_positive = []\n",
    "split_date = date(2021, 7, 7)\n",
    "\n",
    "print(iso_code_list)\n",
    "\n",
    "for code in iso_code_list:\n",
    "    try:\n",
    "        # STEP 1: crea un df con solo data e valore per ogni stato\n",
    "        df_cases = pd.DataFrame(df_new_cases.loc[code]['moving_average_new_cases'].values, index = df_new_cases.loc[code]['moving_average_new_cases'].index, columns = ['moving_average_new_cases'])\n",
    "        df_vaccin = pd.DataFrame(df_vaccination.loc[code]['moving_average_new_vaccinations'].values, index = df_vaccination.loc[code]['moving_average_new_vaccinations'].index, columns = ['moving_average_new_vaccinations'])\n",
    "        \n",
    "        # STEP 2: mergia i due df in uno solo\n",
    "        merged_df = df_cases.merge(df_vaccin, on=['date'])\n",
    "        merged_df.to_csv(f\"./out/ARIMA/tmp/merged_df_{code}.csv\")\n",
    "        \n",
    "        #find split date for df_vaccin that indicate first value not null of 0 for moving_average_new_vaccinations\n",
    "        first_date = merged_df.loc[merged_df['moving_average_new_vaccinations'] > 0].index[0]\n",
    "        last_date = str(split_date.strftime(\"%Y-%m-%d\"))\n",
    "        \n",
    "        merged_df_train = merged_df.loc[(merged_df.index >= first_date) & (merged_df.index <= last_date)].copy()\n",
    "        merged_df_test = merged_df.loc[merged_df.index > last_date].copy()\n",
    "        #print(merged_df_train)\n",
    "        #print(merged_df_test)\n",
    "        \n",
    "        best_model, best_pred, best_d, min_rmse = train_model(merged_df_train, merged_df_test)\n",
    "        \n",
    "        # STEP 4: crea un modello auto_ARIMA per predirre i new_cases considerando i vaccini fino 2 settimane prima dell'inizio delle olimpiadi\n",
    "        model = pm.auto_arima(merged_df_train['moving_average_new_cases'], X=merged_df_train[[\"moving_average_new_vaccinations\"]], start_p=0, start_q=0,\n",
    "                                    test='adf',       # use adftest to find optimal 'd'\n",
    "                                    max_p=3, max_q=3, # maximum p and q\n",
    "                                    d=best_d,          # let model determine 'd'\n",
    "                                    m=4,              # frequency of series\n",
    "                                    error_action='ignore',\n",
    "                                    stagionality=True,\n",
    "                                    suppress_warnings=True,\n",
    "                                    random_state=42,\n",
    "                                    maxiter=500, stationary=False,\n",
    "                                    trace=True,)\n",
    "        \n",
    "        length = len(merged_df_test)\n",
    "        pred, ci = model.predict(n_periods=length, X=merged_df_test[[\"moving_average_new_vaccinations\"]], alpha=0.05, return_conf_int=True)\n",
    "        '''print(\"------------------\")\n",
    "        print(pred)\n",
    "        print(\"------------------\")'''\n",
    "        \n",
    "        #STEP 5: dividi il test set in 3 parti: 14 giorni prima, durante le olimpiadi e 14 giorni dopo    \n",
    "        before_olympic = merged_df_test.loc[merged_df_test.index <= str(split_date + timedelta(days=21))].copy()\n",
    "        first_seven_week__predicted = merged_df_test.loc[(merged_df_test.index > str(split_date + timedelta(days=21))) & (merged_df_test.index <= str(split_date + timedelta(days=28)))].copy()\n",
    "        first_second_week_predicted = merged_df_test.loc[merged_df_test.index > str(split_date + timedelta(days=28)) & (merged_df_test.index <= str(split_date + timedelta(days=35)))].copy()\n",
    "        before_last_game = merged_df_test.loc[merged_df_test.index > str(split_date + timedelta(days=35)) & (merged_df_test.index <= str(split_date + timedelta(days=39)))].copy()\n",
    "        second_seven_week = merged_df_test.loc[merged_df_test.index > str(split_date + timedelta(days=39)) & (merged_df_test.index <= str(split_date + timedelta(days=46)))].copy()\n",
    "        second_second_week = merged_df_test.loc[merged_df_test.index > str(split_date + timedelta(days=46)) & (merged_df_test.index <= str(split_date + timedelta(days=53)))].copy()\n",
    "        after_olympic = merged_df_test.loc[merged_df_test.index > str(split_date + timedelta(days=53))].copy()\n",
    "        \n",
    "        #STEP 6: predici i new_cases\n",
    "        full_olympic_predicted = model.predict(n_periods=len(merged_df_test), X=merged_df_test[[\"moving_average_new_vaccinations\"]])\n",
    "        \n",
    "        # STEP 6.1: sementa la previsione \n",
    "        before_olympic_predicted = full_olympic_predicted[:21]\n",
    "        first_seven_week__predicted = full_olympic_predicted[21:28]\n",
    "        first_second_week_predicted = full_olympic_predicted[28:35]\n",
    "        before_last_game_prediction = full_olympic_predicted[35:39]\n",
    "        second_seven_week_predicted = full_olympic_predicted[39:46]\n",
    "        second_second_week_predicted = full_olympic_predicted[46:53]\n",
    "        after_olympic_predicted = full_olympic_predicted[53:]\n",
    "        \n",
    "        #STEP 7: calcola la media dei new_cases predetti per ogni parte del test set\n",
    "        full_olympic_mean_predicted = full_olympic_predicted.mean()\n",
    "        before_olympic_mean_predicted = full_olympic_predicted[:21].mean()\n",
    "        first_seven_week_mean_predicted = full_olympic_predicted[21:28].mean()\n",
    "        first_second_week_mean_predicted = full_olympic_predicted[28:35].mean()\n",
    "        before_last_game_mean_predicted = full_olympic_predicted[35:39].mean()\n",
    "        second_seven_week_mean_predicted = full_olympic_predicted[39:46].mean()\n",
    "        second_second_week_mean_predicted = full_olympic_predicted[46:53].mean()\n",
    "        after_olympic_mean_predicted = full_olympic_predicted[53:].mean()\n",
    "        \n",
    "        #STEP 8: calcola la differenza tra la media dei new_cases predetti e la media dei new_cases reali\n",
    "        full_olympic_difference = full_olympic_mean_predicted - merged_df_test['moving_average_new_cases'].mean()\n",
    "        before_olympic_difference = before_olympic_mean_predicted - before_olympic['moving_average_new_cases'].mean()\n",
    "        first_seven_week_difference = first_seven_week_mean_predicted - first_seven_week['moving_average_new_cases'].mean()\n",
    "        first_second_week_difference = first_second_week_mean_predicted - first_second_week['moving_average_new_cases'].mean()\n",
    "        before_last_game_difference = before_last_game_mean_predicted - before_last_game['moving_average_new_cases'].mean()\n",
    "        second_seven_week_difference = second_seven_week_mean_predicted - second_seven_week['moving_average_new_cases'].mean()\n",
    "        second_second_week_difference = second_second_week_mean_predicted - second_second_week['moving_average_new_cases'].mean()\n",
    "        after_olympic_difference = after_olympic_mean_predicted - after_olympic['moving_average_new_cases'].mean()\n",
    "        \n",
    "        #STEP 9: calcola la percentuale di differenza tra la media dei new_cases predetti e la media dei new_cases reali\n",
    "        full_olympic_percentage_difference = (full_olympic_difference/merged_df_test['moving_average_new_cases'].mean())*100\n",
    "        before_olympic_percentage_difference = (before_olympic_difference/before_olympic['moving_average_new_cases'].mean())*100\n",
    "        first_seven_week_percentage_difference = (first_seven_week_difference/first_seven_week['moving_average_new_cases'].mean())*100\n",
    "        first_second_week_percentage_difference = (first_second_week_difference/first_second_week['moving_average_new_cases'].mean())*100\n",
    "        before_last_game_percentage_difference = (before_last_game_difference/before_last_game['moving_average_new_cases'].mean())*100\n",
    "        second_seven_week_percentage_difference = (second_seven_week_difference/second_seven_week['moving_average_new_cases'].mean())*100\n",
    "        second_second_week_percentage_difference = (second_second_week_difference/second_second_week['moving_average_new_cases'].mean())*100\n",
    "        after_olympic_percentage_difference = (after_olympic_difference/after_olympic['moving_average_new_cases'].mean())*100\n",
    "        \n",
    "        #STEP 10: clacola rmse\n",
    "        rmse = math.sqrt(mean_squared_error(merged_df_test['moving_average_new_cases'], full_olympic_predicted))\n",
    "        \n",
    "        #STEP 11: salva i risultati in un df\n",
    "        \n",
    "        \n",
    "        #STEP 10: salva i risultati in un df\n",
    "        row = pd.DataFrame.from_dict({'State': code,\n",
    "                                      'Full': full_olympic_percentage_difference,\n",
    "                                      'Before': before_olympic_percentage_difference,\n",
    "                                      'first_week': first_seven_week_percentage_difference,\n",
    "                                      'first_second_week': first_second_week_percentage_difference,\n",
    "                                      'before_last_game': before_last_game_percentage_difference,\n",
    "                                      'second_seven_week': second_seven_week_percentage_difference,\n",
    "                                      'second_second_week': second_second_week_percentage_difference,\n",
    "                                      'After': after_olympic_percentage_difference\n",
    "                                      }, orient='index').T\n",
    "        tabella = pd.concat([tabella, row], ignore_index=True)\n",
    "        \n",
    "        #STEP 11: plot the results\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.plot(merged_df_test.index, merged_df_test['moving_average_new_cases'], label = 'Real new cases')\n",
    "        plt.plot(merged_df_test.index, full_olympic_predicted, label = 'Predicted new cases')\n",
    "        plt.title(code + \" - \" + df_new_cases.loc[code]['Country'].unique()[0])\n",
    "        plt.legend()\n",
    "        \n",
    "        ymax = plt.ylim()[1]\n",
    "        plt.ylim(ymax=ymax*1.20)\n",
    "        \n",
    "        plt.text('2021-07-08', ymax, \"14 days before\\nfirst game of\\nolympic games\", rotation=0, color=\"white\", backgroundcolor=\"blue\")\n",
    "        plt.text('2021-07-22', ymax, \"Olympic \\nGames\", rotation=0, color=\"black\", backgroundcolor=\"yellow\")\n",
    "        plt.text(\"2021-07-29\", ymax, \"7 days \\nafter first metch\", rotation=0, backgroundcolor=\"orange\")\n",
    "        plt.text(\"2021-08-05\", ymax, \"14days \\nafter first metch\", rotation=0, backgroundcolor=\"orange\")\n",
    "        plt.text('2021-08-15', ymax, \"7 days \\nafter last match\", rotation=0, backgroundcolor=\"#FF7D4D\")\n",
    "        plt.text('2021-08-23', ymax, \"14 days \\nafter last match\", rotation=0, backgroundcolor=\"#FF7D4D\")\n",
    "        \n",
    "        plt.axvline(x = '2021-07-08', color = 'blue', label = '14 days before first game of olympic games')\n",
    "        plt.axvspan('2021-07-22', '2021-08-09', facecolor='#ffe206', alpha=0.5)\n",
    "        plt.axvline(x = '2021-07-29', color = 'orange', label = '7 days after first game of olympic games')\n",
    "        plt.axvline(x = '2021-08-05', color = 'orange', label = '14 days after first game of olympic games')\n",
    "        plt.axvline(x = '2021-08-16', color = '#FF7D4D', label = '7 days after last game of olympic games')\n",
    "        plt.axvline(x = '2021-08-23', color = '#FF7D4D', label = '14 days after last game of olympic games')\n",
    "        \n",
    "        plt.xlabel(\"Days since the 28th of July 2021\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylabel(\"Current MA - Previous MA\")\n",
    "        \n",
    "        #save the plot as a png file\n",
    "        plt.savefig(\"../pictures/\"+ code + \"_intervals\" +\".png\")\n",
    "        plt.savefig(\"./out/ARIMA/pictures/\"+ code + \"_intervals\" +\".png\")\n",
    "        plt.show()\n",
    "    except:\n",
    "        print(\"Error in \" + code )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabella is the table for changepoints and tabella2 is the table for the intervals\n",
    "tabella.set_index(tabella['State'])\n",
    "tabella.to_csv(\"./out/ARIMA/ARIMA_tabella.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
