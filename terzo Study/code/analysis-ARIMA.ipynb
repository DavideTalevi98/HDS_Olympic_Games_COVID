{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sdt.changepoint as c\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ARIMA libraries\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics import tsaplots\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pmdarima as pm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from the csv file\n",
    "df_new_cases = pd.read_csv('../data/WHO-COVID-19-global-data.csv')\n",
    "#df_vaccination = pd.read_csv('../data/owid-covid-data.csv')\n",
    "df_vaccination = pd.read_csv('../data/country_vaccinations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add moving average for new cases\n",
    "#df_vaccination['moving_average_new_vaccinations'] = df_vaccination.groupby('iso_code')['new_vaccinations'].transform(lambda x: x.rolling(window=7).mean()) # OWID\n",
    "df_vaccination['moving_average_new_vaccinations'] = df_vaccination.groupby('iso_code')['daily_vaccinations'].transform(lambda x: x.rolling(window=7).mean())\n",
    "\n",
    "# rimuovi tutte le righe che non hanno un valore o hanno un valore a \"0.0\" per moving_average_new_cases\n",
    "df_vaccination = df_vaccination.dropna(subset=['moving_average_new_vaccinations'])\n",
    "df_vaccination = df_vaccination[df_vaccination['moving_average_new_vaccinations'] != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add moving average for new cases\n",
    "df_new_cases['moving_average_new_cases'] = df_new_cases.groupby('Country_code')['New_cases'].transform(lambda x: x.rolling(window=7).mean())\n",
    "\n",
    "# rimuovi tutte le righe che non hanno un valore o hanno un valore a \"0.0\" per moving_average_new_cases\n",
    "df_new_cases = df_new_cases.dropna(subset=['moving_average_new_cases'])\n",
    "df_new_cases = df_new_cases[df_new_cases['moving_average_new_cases'] != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firter data from 2021-07-16 to 2021-08-15\n",
    "start_date = date(2021, 7, 1) \n",
    "og_start_date = date(2021, 7, 22)\n",
    "og_end_date = date(2021, 8, 8)\n",
    "end_date = date(2021, 8, 31)\n",
    "\n",
    "difference = og_start_date - start_date\n",
    "event_duration = og_end_date - og_start_date\n",
    "\n",
    "# filter data from 2021-07-16 to 2021-08-15\n",
    "df_new_cases = df_new_cases[(df_new_cases['Date_reported'] >= str(start_date)) & (df_new_cases['Date_reported'] <= str(end_date))]\n",
    "\n",
    "# filter df_vaccination from 2021-07-16 to 2021-08-15\n",
    "df_vaccination = df_vaccination[(df_vaccination['date'] >= str(start_date)) & (df_vaccination['date'] <= str(end_date))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter by iso_cod that not contain \"OWID\" prefix\n",
    "df_vaccination = df_vaccination[~df_vaccination['iso_code'].str.contains(\"OWID\")]\n",
    "\n",
    "# aggragate by iso_code and date and sum total_cases, total_deaths, population, total_vaccinations, new_cases, mind positive_rate, max positive_rate,KEEP LOCATION \n",
    "#df_vaccination = df_vaccination.groupby(['iso_code', 'date']).agg({'people_vaccinated':'sum', 'new_vaccinations': 'sum', 'location': 'max', 'moving_average_new_vaccinations': 'sum'})\n",
    "df_vaccination = df_vaccination.groupby(['iso_code', 'date']).agg({'total_vaccinations':'sum', 'daily_vaccinations': 'sum', 'country': 'max', 'moving_average_new_vaccinations': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggiungi alla riga attuale nella colonna iso_code il valore iso\n",
    "convert_ISO_3166_2_to_1 = {\n",
    "    'AF':'AFG',\n",
    "    'AX':'ALA',\n",
    "    'AL':'ALB',\n",
    "    'DZ':'DZA',\n",
    "    'AS':'ASM',\n",
    "    'AD':'AND',\n",
    "    'AO':'AGO',\n",
    "    'AI':'AIA',\n",
    "    'AQ':'ATA',\n",
    "    'AG':'ATG',\n",
    "    'AR':'ARG',\n",
    "    'AM':'ARM',\n",
    "    'AW':'ABW',\n",
    "    'AU':'AUS',\n",
    "    'AT':'AUT',\n",
    "    'AZ':'AZE',\n",
    "    'BS':'BHS',\n",
    "    'BH':'BHR',\n",
    "    'BD':'BGD',\n",
    "    'BB':'BRB',\n",
    "    'BY':'BLR',\n",
    "    'BE':'BEL',\n",
    "    'BZ':'BLZ',\n",
    "    'BJ':'BEN',\n",
    "    'BM':'BMU',\n",
    "    'BT':'BTN',\n",
    "    'BO':'BOL',\n",
    "    'BA':'BIH',\n",
    "    'BW':'BWA',\n",
    "    'BV':'BVT',\n",
    "    'BR':'BRA',\n",
    "    'IO':'IOT',\n",
    "    'BN':'BRN',\n",
    "    'BG':'BGR',\n",
    "    'BF':'BFA',\n",
    "    'BI':'BDI',\n",
    "    'KH':'KHM',\n",
    "    'CM':'CMR',\n",
    "    'CA':'CAN',\n",
    "    'CV':'CPV',\n",
    "    'KY':'CYM',\n",
    "    'CF':'CAF',\n",
    "    'TD':'TCD',\n",
    "    'CL':'CHL',\n",
    "    'CN':'CHN',\n",
    "    'CX':'CXR',\n",
    "    'CC':'CCK',\n",
    "    'CO':'COL',\n",
    "    'KM':'COM',\n",
    "    'CG':'COG',\n",
    "    'CD':'COD',\n",
    "    'CK':'COK',\n",
    "    'CR':'CRI',\n",
    "    'CI':'CIV',\n",
    "    'HR':'HRV',\n",
    "    'CU':'CUB',\n",
    "    'CY':'CYP',\n",
    "    'CZ':'CZE',\n",
    "    'DK':'DNK',\n",
    "    'DJ':'DJI',\n",
    "    'DM':'DMA',\n",
    "    'DO':'DOM',\n",
    "    'EC':'ECU',\n",
    "    'EG':'EGY',\n",
    "    'SV':'SLV',\n",
    "    'GQ':'GNQ',\n",
    "    'ER':'ERI',\n",
    "    'EE':'EST',\n",
    "    'ET':'ETH',\n",
    "    'FK':'FLK',\n",
    "    'FO':'FRO',\n",
    "    'FJ':'FJI',\n",
    "    'FI':'FIN',\n",
    "    'FR':'FRA',\n",
    "    'GF':'GUF',\n",
    "    'PF':'PYF',\n",
    "    'TF':'ATF',\n",
    "    'GA':'GAB',\n",
    "    'GM':'GMB',\n",
    "    'GE':'GEO',\n",
    "    'DE':'DEU',\n",
    "    'GH':'GHA',\n",
    "    'GI':'GIB',\n",
    "    'GR':'GRC',\n",
    "    'GL':'GRL',\n",
    "    'GD':'GRD',\n",
    "    'GP':'GLP',\n",
    "    'GU':'GUM',\n",
    "    'GT':'GTM',\n",
    "    'GG':'GGY',\n",
    "    'GN':'GIN',\n",
    "    'GW':'GNB',\n",
    "    'GY':'GUY',\n",
    "    'HT':'HTI',\n",
    "    'HM':'HMD',\n",
    "    'VA':'VAT',\n",
    "    'HN':'HND',\n",
    "    'HK':'HKG',\n",
    "    'HU':'HUN',\n",
    "    'IS':'ISL',\n",
    "    'IN':'IND',\n",
    "    'ID':'IDN',\n",
    "    'IR':'IRN',\n",
    "    'IQ':'IRQ',\n",
    "    'IE':'IRL',\n",
    "    'IM':'IMN',\n",
    "    'IL':'ISR',\n",
    "    'IT':'ITA',\n",
    "    'JM':'JAM',\n",
    "    'JP':'JPN',\n",
    "    'JE':'JEY',\n",
    "    'JO':'JOR',\n",
    "    'KZ':'KAZ',\n",
    "    'KE':'KEN',\n",
    "    'KI':'KIR',\n",
    "    'KP':'PRK',\n",
    "    'KR':'KOR',\n",
    "    'KW':'KWT',\n",
    "    'KG':'KGZ',\n",
    "    'LA':'LAO',\n",
    "    'LV':'LVA',\n",
    "    'LB':'LBN',\n",
    "    'LS':'LSO',\n",
    "    'LR':'LBR',\n",
    "    'LY':'LBY',\n",
    "    'LI':'LIE',\n",
    "    'LT':'LTU',\n",
    "    'LU':'LUX',\n",
    "    'MO':'MAC',\n",
    "    'MK':'MKD',\n",
    "    'MG':'MDG',\n",
    "    'MW':'MWI',\n",
    "    'MY':'MYS',\n",
    "    'MV':'MDV',\n",
    "    'ML':'MLI',\n",
    "    'MT':'MLT',\n",
    "    'MH':'MHL',\n",
    "    'MQ':'MTQ',\n",
    "    'MR':'MRT',\n",
    "    'MU':'MUS',\n",
    "    'YT':'MYT',\n",
    "    'MX':'MEX',\n",
    "    'FM':'FSM',\n",
    "    'MD':'MDA',\n",
    "    'MC':'MCO',\n",
    "    'MN':'MNG',\n",
    "    'ME':'MNE',\n",
    "    'MS':'MSR',\n",
    "    'MA':'MAR',\n",
    "    'MZ':'MOZ',\n",
    "    'MM':'MMR',\n",
    "    'NA':'NAM',\n",
    "    'NR':'NRU',\n",
    "    'NP':'NPL',\n",
    "    'NL':'NLD',\n",
    "    'AN':'ANT',\n",
    "    'NC':'NCL',\n",
    "    'NZ':'NZL',\n",
    "    'NI':'NIC',\n",
    "    'NE':'NER',\n",
    "    'NG':'NGA',\n",
    "    'NU':'NIU',\n",
    "    'NF':'NFK',\n",
    "    'MP':'MNP',\n",
    "    'NO':'NOR',\n",
    "    'OM':'OMN',\n",
    "    'PK':'PAK',\n",
    "    'PW':'PLW',\n",
    "    'PS':'PSE',\n",
    "    'PA':'PAN',\n",
    "    'PG':'PNG',\n",
    "    'PY':'PRY',\n",
    "    'PE':'PER',\n",
    "    'PH':'PHL',\n",
    "    'PN':'PCN',\n",
    "    'PL':'POL',\n",
    "    'PT':'PRT',\n",
    "    'PR':'PRI',\n",
    "    'QA':'QAT',\n",
    "    'RE':'REU',\n",
    "    'RO':'ROU',\n",
    "    'RU':'RUS',\n",
    "    'RW':'RWA',\n",
    "    'BL':'BLM',\n",
    "    'SH':'SHN',\n",
    "    'KN':'KNA',\n",
    "    'LC':'LCA',\n",
    "    'MF':'MAF',\n",
    "    'PM':'SPM',\n",
    "    'VC':'VCT',\n",
    "    'WS':'WSM',\n",
    "    'SM':'SMR',\n",
    "    'ST':'STP',\n",
    "    'SA':'SAU',\n",
    "    'SN':'SEN',\n",
    "    'RS':'SRB',\n",
    "    'SC':'SYC',\n",
    "    'SL':'SLE',\n",
    "    'SG':'SGP',\n",
    "    'SK':'SVK',\n",
    "    'SI':'SVN',\n",
    "    'SB':'SLB',\n",
    "    'SO':'SOM',\n",
    "    'ZA':'ZAF',\n",
    "    'GS':'SGS',\n",
    "    'ES':'ESP',\n",
    "    'LK':'LKA',\n",
    "    'SD':'SDN',\n",
    "    'SR':'SUR',\n",
    "    'SJ':'SJM',\n",
    "    'SZ':'SWZ',\n",
    "    'SE':'SWE',\n",
    "    'CH':'CHE',\n",
    "    'SY':'SYR',\n",
    "    'TW':'TWN',\n",
    "    'TJ':'TJK',\n",
    "    'TZ':'TZA',\n",
    "    'TH':'THA',\n",
    "    'TL':'TLS',\n",
    "    'TG':'TGO',\n",
    "    'TK':'TKL',\n",
    "    'TO':'TON',\n",
    "    'TT':'TTO',\n",
    "    'TN':'TUN',\n",
    "    'TR':'TUR',\n",
    "    'TM':'TKM',\n",
    "    'TC':'TCA',\n",
    "    'TV':'TUV',\n",
    "    'UG':'UGA',\n",
    "    'UA':'UKR',\n",
    "    'AE':'ARE',\n",
    "    'GB':'GBR',\n",
    "    'US':'USA',\n",
    "    'UM':'UMI',\n",
    "    'UY':'URY',\n",
    "    'UZ':'UZB',\n",
    "    'VU':'VUT',\n",
    "    'VE':'VEN',\n",
    "    'VN':'VNM',\n",
    "    'VG':'VGB',\n",
    "    'VI':'VIR',\n",
    "    'WF':'WLF',\n",
    "    'EH':'ESH',\n",
    "    'YE':'YEM',\n",
    "    'ZM':'ZMB',\n",
    "    'ZW':'ZWE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set country_code like index\n",
    "df_new_cases = df_new_cases.set_index('Country_code')\n",
    "country_list = df_new_cases.index.get_level_values('Country_code').unique()\n",
    "\n",
    "for code in country_list:\n",
    "    if code not in country_code_to_iso:\n",
    "        print(code , \"NOT FOUND\")\n",
    "        continue\n",
    "    iso = country_code_to_iso[code]\n",
    "    df_new_cases.loc[(df_new_cases.index.get_level_values('Country_code') == code), 'iso_code'] = iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns of date_reported\n",
    "df_new_cases.rename(columns={'Date_reported':'date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggragate by iso_code and date and sum total_cases, total_deaths, population, total_vaccinations, new_cases, mind positive_rate, max positive_rate,KEEP LOCATION \n",
    "df_new_cases = df_new_cases.groupby(['iso_code', 'date']).agg({'Country': 'sum', 'WHO_region': 'sum', 'New_cases': 'sum', 'Cumulative_cases': 'sum', 'New_deaths': 'sum', 'Cumulative_deaths': 'sum', 'moving_average_new_cases': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe in csv file\n",
    "df_new_cases.to_csv('./dataframe.csv')\n",
    "df_vaccination.to_csv('./vaccinations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for iso_code in df_vaccination.index.get_level_values(\\'iso_code\\').unique():\\n    plt.plot(df_vaccination.loc[iso_code][\\'moving_average_new_vaccinations\\'], label=\\'vaccinations\\')\\n    plt.title(df_vaccination.loc[iso_code][\\'country\\'].unique()[0])\\n    plt.ylabel(\"new vaccinations\")\\n    plt.xlabel(\"Date\")\\n    plt.xticks(rotation=90)\\n    plt.show()'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for iso_code in df_vaccination.index.get_level_values('iso_code').unique():\n",
    "    plt.plot(df_vaccination.loc[iso_code]['moving_average_new_vaccinations'], label='vaccinations')\n",
    "    plt.title(df_vaccination.loc[iso_code]['country'].unique()[0])\n",
    "    plt.ylabel(\"new vaccinations\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# crea una lista di tutti gli iso_code presenti in df_new_cases\n",
    "iso_code_list = df_new_cases.index.get_level_values('iso_code').unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'iso_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kg/hb0xn_9j3m74zfkmc9xxzcv00000gn/T/ipykernel_49464/2175455772.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#crea un df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdf_cases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_new_cases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'moving_average_new_cases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'new_cases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdf_vaccin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_vaccination\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'moving_average_new_vaccinations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_vaccination\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'moving_average_new_vaccinations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'new_vaccinations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_cases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_vaccination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iso_code'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   9839\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9840\u001b[0m     ) -> DataFrame:\n\u001b[1;32m   9841\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9843\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m   9844\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9845\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9846\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mindicator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m ) -> DataFrame:\n\u001b[0;32m--> 148\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    733\u001b[0m         (\n\u001b[1;32m    734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1217\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m                         \u001b[0;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'iso_code'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "#interval technique\n",
    "BayesOffline = c.BayesOffline()\n",
    "media_changepoint = 0.0\n",
    "count_changepoint = 0.0\n",
    "min_changepoint = (999,\"error\")\n",
    "max_changepoint = (-1,\"error\")\n",
    "save_me = []\n",
    "tabella = pd.DataFrame(columns=['State','FirstSlope','SecondSlope','ThirdSlope','FourthSlope'])\n",
    "trend_negative = []\n",
    "trend_positive = []\n",
    "\n",
    "for code in iso_code_list:\n",
    "    # Out is a list of possible changepoint \"indices\"\n",
    "    values = df_new_cases.loc[code]['moving_average_new_cases'].values\n",
    "    \n",
    "    #crea un df \n",
    "    df_cases = pd.DataFrame(values, index = df_new_cases.loc[code]['moving_average_new_cases'].index, columns = ['new_cases'])\n",
    "    df_vaccin = pd.DataFrame(df_vaccination.loc[code]['moving_average_new_vaccinations'].values, index = df_vaccination.loc[code]['moving_average_new_vaccinations'].index, columns = ['new_vaccinations'])\n",
    "    \n",
    "    merged_df = df_cases.merge(df_vaccination, on=['iso_code', 'date'])\n",
    "    print(merged_df)\n",
    "    print(merged_df.index)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # crea un df con i valori di new_cases e indice le righe con le date\n",
    "    df = pd.DataFrame(values, index = df_vaccination.loc[code]['moving_average_new_vaccinations'].index, columns = ['new_cases'])\n",
    "    print(df)\n",
    "    print(df.index)\n",
    "    \n",
    "    #splitta il df in due dataframe di training e di test con split date\n",
    "    df_train = df.loc[df.index <= str(split_date)].copy()\n",
    "    df_test = df.loc[df.index > str(split_date)].copy()\n",
    "    \n",
    "    \n",
    "    # crea un modello ARIMA per predirre i new_cases considerando i vaccini fino 2 settimane prima dell'inizio delle olimpiadi\n",
    "    ARIMAModel = ARIMA(df_train, order=(1,1,1))\n",
    "    ARIMAModel_fit = ARIMAModel.fit()\n",
    "    ARIMAModel_fit.summary()\n",
    "    # predice i new_cases per le due settimane delle olimpiadi\n",
    "    ARIMAModel_fit.predict(start = len(df_train), end = len(df_train)+13)\n",
    "    # calcola la media dei new_cases predetti\n",
    "    mean_predicted = ARIMAModel_fit.predict(start = len(df_train), end = len(df_train)+13).mean()\n",
    "    # calcola la media dei new_cases reali\n",
    "    mean_real = df_test.mean()\n",
    "    # calcola la differenza tra la media dei new_cases predetti e la media dei new_cases reali\n",
    "    difference = mean_predicted - mean_real\n",
    "    # calcola la percentuale di differenza tra la media dei new_cases predetti e la media dei new_cases reali\n",
    "    percentage_difference = (difference/mean_real)*100\n",
    "    print(\"The mean of the predicted new cases is: \" + str(mean_predicted))\n",
    "    \n",
    "    # plot the predicted values\n",
    "    plt.plot(ARIMAModel_fit.predict(start = len(df_train), end = len(df_train)+13), color = 'red', label = 'Predicted new cases')\n",
    "    # plot the real values\n",
    "    plt.plot(df_test, color = 'blue', label = 'Real new cases')\n",
    "    plt.title(code + \" - \" + df_new_cases.loc[code]['Country'].unique()[0])\n",
    "    plt.xlabel(\"Days since the 28th of July 2021\")\n",
    "    plt.ylabel(\"Current MA - Previous MA\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    '''df2 = df_new_cases.loc[code]['moving_average_new_cases']\n",
    "    # Questa riga estrae i valori della colonna \"Data\" del dataframe df dalla prima data del dataframe alla data del lockdown.\n",
    "    values_before = df2.iloc[:difference.days+1].values\n",
    "    # Questa riga estrae i valori della colonna \"Data\" del dataframe df dalla data del lockdown fino alla settimana successiva 4.\n",
    "    values_oneWeek = df2.iloc[difference.days+1:difference.days+8].values\n",
    "    # Questa riga estrae i valori della colonna \"Data\" del dataframe df dalla data del lockdown fino alla settimana successiva 5.\n",
    "    values_twoWeek = df2.iloc[difference.days+8:difference.days+15].values\n",
    "    # Questa riga estrae i valori della colonna \"Data\" del dataframe df dalla data del lockdown fino alla settimana successiva 6.\n",
    "    values_after = df2.iloc[difference.days+15:].values\n",
    "\n",
    "\n",
    "    z1 = np.polyfit(range(0,len(values_before)), values_before, 1)\n",
    "    p1 = np.poly1d(z1)\n",
    "    z2 = np.polyfit(range(len(values_before),len(values_before)+len(values_oneWeek)), values_oneWeek, 1)\n",
    "    p2 = np.poly1d(z2)\n",
    "    z3 = np.polyfit(range(len(values_before)+len(values_oneWeek),len(values_before)+len(values_oneWeek)+len(values_twoWeek)), values_twoWeek, 1)\n",
    "    p3 = np.poly1d(z3)\n",
    "    z4 = np.polyfit(range(len(values_before)+len(values_oneWeek)+len(values_twoWeek),len(values_before)+len(values_oneWeek)+len(values_twoWeek)+len(values_after)), values_after, 1)\n",
    "    p4 = np.poly1d(z4)\n",
    "    \n",
    "    entry = pd.DataFrame.from_dict({\"State\": code,'FirstSlope': [z1[0]],'SecondSlope': [z2[0]],'ThirdSlope': [z3[0]],'FourthSlope': [z4[0]]})\n",
    "    tabella = pd.concat([tabella2, entry], ignore_index=True)\n",
    "\n",
    "    array1 = np.arange(0,len(values_before))\n",
    "    array2 = np.arange(len(values_before),len(values_before)+len(values_oneWeek))\n",
    "    array2 = np.insert(array2, 0, array1[-1])\n",
    "    array3 = np.arange(len(values_before)+len(values_oneWeek),len(values_before)+len(values_oneWeek)+len(values_twoWeek))\n",
    "    array3 = np.insert(array3, 0, array2[-1])\n",
    "    array4 = np.arange(len(values_before)+len(values_oneWeek)+len(values_twoWeek),len(values_before)+len(values_oneWeek)+len(values_twoWeek)+len(values_after))\n",
    "    array4 = np.insert(array4, 0, array3[-1])\n",
    "    lw = 2\n",
    "    \n",
    "\n",
    "    plt.plot(array1, p1(range(0,len(values_before))), color=\"#0B1F65\", linewidth=lw, linestyle=\"dashdot\")\n",
    "    plt.plot(array2, p2(range(len(values_before)-1,len(values_before)+len(values_oneWeek))), color=\"#116530\", linewidth=lw, linestyle=\"dashdot\")\n",
    "    plt.plot(array3, p3(range(len(values_before)+len(values_oneWeek)-1,len(values_before)+len(values_oneWeek)+len(values_twoWeek))), color=\"#D7A449\", linewidth=lw, linestyle=\"dashdot\")\n",
    "    plt.plot(array4, p4(range(len(values_before)+len(values_oneWeek)+len(values_twoWeek)-1,len(values_before)+len(values_oneWeek)+len(values_twoWeek)+len(values_after))), color=\"#DB3F29\", linewidth=lw, linestyle=\"dashdot\")\n",
    "    '''\n",
    "    # Crea un plot con i punti di cambio colorati\n",
    "    plt.title(code + \" - \" + df_new_cases.loc[code]['Country'].unique()[0])\n",
    "    plt.axvline(x = difference.days-14, color = 'blue', label = '14 days before first game of olympic games')\n",
    "    plt.axvline(x = difference.days+7, color = 'orange', label = '7 days after first game of olympic games')\n",
    "    plt.axvline(x = difference.days+18, color = '#FF7D4D', label = '7 days after last game of olympic games')\n",
    "    plt.xlabel(\"Days since the 28th of July 2021\")\n",
    "    plt.ylabel(\"Current MA - Previous MA\")\n",
    "    #plt.legend()\n",
    "    plt.axvspan(difference.days, difference.days+11, facecolor='#ffe206', alpha=0.5)\n",
    "    ymax = plt.ylim()[1]\n",
    "    # aggiungi un margine di 5% sopra il massimo valore per far spazio alle etichette\n",
    "    plt.ylim(ymax=ymax*1.20)\n",
    "    plt.text(difference.days-14, ymax, \"14 days before\\nfirst game of\\nolympic games\", rotation=0, color=\"white\", backgroundcolor=\"blue\")\n",
    "    plt.text(difference.days, ymax, \"Olympic \\nGames\", rotation=0, color=\"black\", backgroundcolor=\"yellow\")\n",
    "    plt.text(difference.days+7+1, ymax, \"7 days \\nafter first metch\", rotation=0, backgroundcolor=\"orange\")\n",
    "    plt.text(difference.days+18+1, ymax, \"7 days \\nafter last match\", rotation=0, backgroundcolor=\"#FF7D4D\")\n",
    "    #save the plot as a png file\n",
    "    plt.savefig(\"../pictures/\"+ code + \"_intervals\" +\".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabella is the table for changepoints and tabella2 is the table for the intervals\n",
    "tabella.set_index(tabella['State'])\n",
    "tabella.to_csv(\"./tabella.csv\", index=False)\n",
    "\n",
    "tabella2.set_index(tabella2['State'])\n",
    "tabella2.to_csv(\"./tabella2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
