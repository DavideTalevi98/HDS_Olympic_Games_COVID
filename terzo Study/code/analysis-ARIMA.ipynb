{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sdt.changepoint as c\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ARIMA libraries\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics import tsaplots\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pmdarima as pm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from the csv file\n",
    "df_new_cases = pd.read_csv('../data/WHO-COVID-19-global-data.csv')\n",
    "#df_vaccination = pd.read_csv('../data/owid-covid-data.csv')\n",
    "df_vaccination = pd.read_csv('../data/country_vaccinations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add moving average for new cases\n",
    "#df_vaccination['moving_average_new_vaccinations'] = df_vaccination.groupby('iso_code')['new_vaccinations'].transform(lambda x: x.rolling(window=7).mean()) # OWID\n",
    "df_vaccination['moving_average_new_vaccinations'] = df_vaccination.groupby('iso_code')['daily_vaccinations'].transform(lambda x: x.rolling(window=7).mean())\n",
    "\n",
    "# rimuovi tutte le righe che non hanno un valore o hanno un valore a \"0.0\" per moving_average_new_cases\n",
    "df_vaccination = df_vaccination.dropna(subset=['moving_average_new_vaccinations'])\n",
    "df_vaccination = df_vaccination[df_vaccination['moving_average_new_vaccinations'] != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add moving average for new cases\n",
    "df_new_cases['moving_average_new_cases'] = df_new_cases.groupby('Country_code')['New_cases'].transform(lambda x: x.rolling(window=7).mean())\n",
    "\n",
    "# rimuovi tutte le righe che non hanno un valore o hanno un valore a \"0.0\" per moving_average_new_cases\n",
    "df_new_cases = df_new_cases.dropna(subset=['moving_average_new_cases'])\n",
    "df_new_cases = df_new_cases[df_new_cases['moving_average_new_cases'] != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firter data from 2021-07-16 to 2021-08-15\n",
    "start_date = date(2021, 1, 1) \n",
    "og_start_date = date(2021, 7, 22)\n",
    "og_end_date = date(2021, 8, 8)\n",
    "end_date = date(2021, 8, 31)\n",
    "\n",
    "difference = og_start_date - start_date\n",
    "event_duration = og_end_date - og_start_date\n",
    "\n",
    "# filter data from 2021-07-16 to 2021-08-15\n",
    "df_new_cases = df_new_cases[(df_new_cases['Date_reported'] >= str(start_date)) & (df_new_cases['Date_reported'] <= str(end_date))]\n",
    "\n",
    "# filter df_vaccination from 2021-07-16 to 2021-08-15\n",
    "df_vaccination = df_vaccination[(df_vaccination['date'] >= str(start_date)) & (df_vaccination['date'] <= str(end_date))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter by iso_cod that not contain \"OWID\" prefix\n",
    "df_vaccination = df_vaccination[~df_vaccination['iso_code'].str.contains(\"OWID\")]\n",
    "\n",
    "# aggragate by iso_code and date and sum total_cases, total_deaths, population, total_vaccinations, new_cases, mind positive_rate, max positive_rate,KEEP LOCATION \n",
    "#df_vaccination = df_vaccination.groupby(['iso_code', 'date']).agg({'people_vaccinated':'sum', 'new_vaccinations': 'sum', 'location': 'max', 'moving_average_new_vaccinations': 'sum'})\n",
    "df_vaccination = df_vaccination.groupby(['iso_code', 'date']).agg({'total_vaccinations':'sum', 'daily_vaccinations': 'sum', 'country': 'max', 'moving_average_new_vaccinations': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggiungi alla riga attuale nella colonna iso_code il valore iso\n",
    "convert_ISO_3166_2_to_1 = {\n",
    "    'AF':'AFG',\n",
    "    'AX':'ALA',\n",
    "    'AL':'ALB',\n",
    "    'DZ':'DZA',\n",
    "    'AS':'ASM',\n",
    "    'AD':'AND',\n",
    "    'AO':'AGO',\n",
    "    'AI':'AIA',\n",
    "    'AQ':'ATA',\n",
    "    'AG':'ATG',\n",
    "    'AR':'ARG',\n",
    "    'AM':'ARM',\n",
    "    'AW':'ABW',\n",
    "    'AU':'AUS',\n",
    "    'AT':'AUT',\n",
    "    'AZ':'AZE',\n",
    "    'BS':'BHS',\n",
    "    'BH':'BHR',\n",
    "    'BD':'BGD',\n",
    "    'BB':'BRB',\n",
    "    'BY':'BLR',\n",
    "    'BE':'BEL',\n",
    "    'BZ':'BLZ',\n",
    "    'BJ':'BEN',\n",
    "    'BM':'BMU',\n",
    "    'BT':'BTN',\n",
    "    'BO':'BOL',\n",
    "    'BA':'BIH',\n",
    "    'BW':'BWA',\n",
    "    'BV':'BVT',\n",
    "    'BR':'BRA',\n",
    "    'IO':'IOT',\n",
    "    'BN':'BRN',\n",
    "    'BG':'BGR',\n",
    "    'BF':'BFA',\n",
    "    'BI':'BDI',\n",
    "    'KH':'KHM',\n",
    "    'CM':'CMR',\n",
    "    'CA':'CAN',\n",
    "    'CV':'CPV',\n",
    "    'KY':'CYM',\n",
    "    'CF':'CAF',\n",
    "    'TD':'TCD',\n",
    "    'CL':'CHL',\n",
    "    'CN':'CHN',\n",
    "    'CX':'CXR',\n",
    "    'CC':'CCK',\n",
    "    'CO':'COL',\n",
    "    'KM':'COM',\n",
    "    'CG':'COG',\n",
    "    'CD':'COD',\n",
    "    'CK':'COK',\n",
    "    'CR':'CRI',\n",
    "    'CI':'CIV',\n",
    "    'HR':'HRV',\n",
    "    'CU':'CUB',\n",
    "    'CY':'CYP',\n",
    "    'CZ':'CZE',\n",
    "    'DK':'DNK',\n",
    "    'DJ':'DJI',\n",
    "    'DM':'DMA',\n",
    "    'DO':'DOM',\n",
    "    'EC':'ECU',\n",
    "    'EG':'EGY',\n",
    "    'SV':'SLV',\n",
    "    'GQ':'GNQ',\n",
    "    'ER':'ERI',\n",
    "    'EE':'EST',\n",
    "    'ET':'ETH',\n",
    "    'FK':'FLK',\n",
    "    'FO':'FRO',\n",
    "    'FJ':'FJI',\n",
    "    'FI':'FIN',\n",
    "    'FR':'FRA',\n",
    "    'GF':'GUF',\n",
    "    'PF':'PYF',\n",
    "    'TF':'ATF',\n",
    "    'GA':'GAB',\n",
    "    'GM':'GMB',\n",
    "    'GE':'GEO',\n",
    "    'DE':'DEU',\n",
    "    'GH':'GHA',\n",
    "    'GI':'GIB',\n",
    "    'GR':'GRC',\n",
    "    'GL':'GRL',\n",
    "    'GD':'GRD',\n",
    "    'GP':'GLP',\n",
    "    'GU':'GUM',\n",
    "    'GT':'GTM',\n",
    "    'GG':'GGY',\n",
    "    'GN':'GIN',\n",
    "    'GW':'GNB',\n",
    "    'GY':'GUY',\n",
    "    'HT':'HTI',\n",
    "    'HM':'HMD',\n",
    "    'VA':'VAT',\n",
    "    'HN':'HND',\n",
    "    'HK':'HKG',\n",
    "    'HU':'HUN',\n",
    "    'IS':'ISL',\n",
    "    'IN':'IND',\n",
    "    'ID':'IDN',\n",
    "    'IR':'IRN',\n",
    "    'IQ':'IRQ',\n",
    "    'IE':'IRL',\n",
    "    'IM':'IMN',\n",
    "    'IL':'ISR',\n",
    "    'IT':'ITA',\n",
    "    'JM':'JAM',\n",
    "    'JP':'JPN',\n",
    "    'JE':'JEY',\n",
    "    'JO':'JOR',\n",
    "    'KZ':'KAZ',\n",
    "    'KE':'KEN',\n",
    "    'KI':'KIR',\n",
    "    'KP':'PRK',\n",
    "    'KR':'KOR',\n",
    "    'KW':'KWT',\n",
    "    'KG':'KGZ',\n",
    "    'LA':'LAO',\n",
    "    'LV':'LVA',\n",
    "    'LB':'LBN',\n",
    "    'LS':'LSO',\n",
    "    'LR':'LBR',\n",
    "    'LY':'LBY',\n",
    "    'LI':'LIE',\n",
    "    'LT':'LTU',\n",
    "    'LU':'LUX',\n",
    "    'MO':'MAC',\n",
    "    'MK':'MKD',\n",
    "    'MG':'MDG',\n",
    "    'MW':'MWI',\n",
    "    'MY':'MYS',\n",
    "    'MV':'MDV',\n",
    "    'ML':'MLI',\n",
    "    'MT':'MLT',\n",
    "    'MH':'MHL',\n",
    "    'MQ':'MTQ',\n",
    "    'MR':'MRT',\n",
    "    'MU':'MUS',\n",
    "    'YT':'MYT',\n",
    "    'MX':'MEX',\n",
    "    'FM':'FSM',\n",
    "    'MD':'MDA',\n",
    "    'MC':'MCO',\n",
    "    'MN':'MNG',\n",
    "    'ME':'MNE',\n",
    "    'MS':'MSR',\n",
    "    'MA':'MAR',\n",
    "    'MZ':'MOZ',\n",
    "    'MM':'MMR',\n",
    "    'NA':'NAM',\n",
    "    'NR':'NRU',\n",
    "    'NP':'NPL',\n",
    "    'NL':'NLD',\n",
    "    'AN':'ANT',\n",
    "    'NC':'NCL',\n",
    "    'NZ':'NZL',\n",
    "    'NI':'NIC',\n",
    "    'NE':'NER',\n",
    "    'NG':'NGA',\n",
    "    'NU':'NIU',\n",
    "    'NF':'NFK',\n",
    "    'MP':'MNP',\n",
    "    'NO':'NOR',\n",
    "    'OM':'OMN',\n",
    "    'PK':'PAK',\n",
    "    'PW':'PLW',\n",
    "    'PS':'PSE',\n",
    "    'PA':'PAN',\n",
    "    'PG':'PNG',\n",
    "    'PY':'PRY',\n",
    "    'PE':'PER',\n",
    "    'PH':'PHL',\n",
    "    'PN':'PCN',\n",
    "    'PL':'POL',\n",
    "    'PT':'PRT',\n",
    "    'PR':'PRI',\n",
    "    'QA':'QAT',\n",
    "    'RE':'REU',\n",
    "    'RO':'ROU',\n",
    "    'RU':'RUS',\n",
    "    'RW':'RWA',\n",
    "    'BL':'BLM',\n",
    "    'SH':'SHN',\n",
    "    'KN':'KNA',\n",
    "    'LC':'LCA',\n",
    "    'MF':'MAF',\n",
    "    'PM':'SPM',\n",
    "    'VC':'VCT',\n",
    "    'WS':'WSM',\n",
    "    'SM':'SMR',\n",
    "    'ST':'STP',\n",
    "    'SA':'SAU',\n",
    "    'SN':'SEN',\n",
    "    'RS':'SRB',\n",
    "    'SC':'SYC',\n",
    "    'SL':'SLE',\n",
    "    'SG':'SGP',\n",
    "    'SK':'SVK',\n",
    "    'SI':'SVN',\n",
    "    'SB':'SLB',\n",
    "    'SO':'SOM',\n",
    "    'ZA':'ZAF',\n",
    "    'GS':'SGS',\n",
    "    'ES':'ESP',\n",
    "    'LK':'LKA',\n",
    "    'SD':'SDN',\n",
    "    'SR':'SUR',\n",
    "    'SJ':'SJM',\n",
    "    'SZ':'SWZ',\n",
    "    'SE':'SWE',\n",
    "    'CH':'CHE',\n",
    "    'SY':'SYR',\n",
    "    'TW':'TWN',\n",
    "    'TJ':'TJK',\n",
    "    'TZ':'TZA',\n",
    "    'TH':'THA',\n",
    "    'TL':'TLS',\n",
    "    'TG':'TGO',\n",
    "    'TK':'TKL',\n",
    "    'TO':'TON',\n",
    "    'TT':'TTO',\n",
    "    'TN':'TUN',\n",
    "    'TR':'TUR',\n",
    "    'TM':'TKM',\n",
    "    'TC':'TCA',\n",
    "    'TV':'TUV',\n",
    "    'UG':'UGA',\n",
    "    'UA':'UKR',\n",
    "    'AE':'ARE',\n",
    "    'GB':'GBR',\n",
    "    'US':'USA',\n",
    "    'UM':'UMI',\n",
    "    'UY':'URY',\n",
    "    'UZ':'UZB',\n",
    "    'VU':'VUT',\n",
    "    'VE':'VEN',\n",
    "    'VN':'VNM',\n",
    "    'VG':'VGB',\n",
    "    'VI':'VIR',\n",
    "    'WF':'WLF',\n",
    "    'EH':'ESH',\n",
    "    'YE':'YEM',\n",
    "    'ZM':'ZMB',\n",
    "    'ZW':'ZWE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set country_code like index\n",
    "df_new_cases = df_new_cases.set_index('Country_code')\n",
    "country_list = df_new_cases.index.get_level_values('Country_code').unique()\n",
    "\n",
    "for code in country_list:\n",
    "    if code not in convert_ISO_3166_2_to_1:\n",
    "        #print(code , \"NOT FOUND\")\n",
    "        continue\n",
    "    iso = convert_ISO_3166_2_to_1[code]\n",
    "    df_new_cases.loc[(df_new_cases.index.get_level_values('Country_code') == code), 'iso_code'] = iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns of date_reported\n",
    "df_new_cases.rename(columns={'Date_reported':'date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggragate by iso_code and date and sum total_cases, total_deaths, population, total_vaccinations, new_cases, mind positive_rate, max positive_rate,KEEP LOCATION \n",
    "df_new_cases = df_new_cases.groupby(['iso_code', 'date']).agg({'Country': 'sum', 'New_cases': 'sum', 'moving_average_new_cases': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe in csv file\n",
    "df_new_cases.to_csv('./dataframe.csv')\n",
    "df_vaccination.to_csv('./vaccinations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for iso_code in df_vaccination.index.get_level_values(\\'iso_code\\').unique():\\n    plt.plot(df_vaccination.loc[iso_code][\\'moving_average_new_vaccinations\\'], label=\\'vaccinations\\')\\n    plt.title(df_vaccination.loc[iso_code][\\'country\\'].unique()[0])\\n    plt.ylabel(\"new vaccinations\")\\n    plt.xlabel(\"Date\")\\n    plt.xticks(rotation=90)\\n    plt.show()'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for iso_code in df_vaccination.index.get_level_values('iso_code').unique():\n",
    "    plt.plot(df_vaccination.loc[iso_code]['moving_average_new_vaccinations'], label='vaccinations')\n",
    "    plt.title(df_vaccination.loc[iso_code]['country'].unique()[0])\n",
    "    plt.ylabel(\"new vaccinations\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# crea una lista di tutti gli iso_code presenti in df_new_cases\n",
    "iso_code_list = df_new_cases.index.get_level_values('iso_code').unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df_train, df_test):\n",
    "    min_rmse = 10000000\n",
    "    best_model = None\n",
    "    best_d = 0\n",
    "    best_pred = None\n",
    "    for diff in range(0, 3):\n",
    "        model = pm.auto_arima(df_train[\"moving_average_new_cases\"], X=df_train[\"moving_average_new_vaccinations\"], start_p=0, start_q=0,\n",
    "                              # usiamo il test adf per la stazionarietÃ .\n",
    "                              test='adf',\n",
    "                              max_p=5, max_q=5,\n",
    "                              d=diff,  # ordine della prima differenziazione\n",
    "                              error_action='ignore', trace=True,\n",
    "                              suppress_warnings=True,\n",
    "                              random_state=42,\n",
    "                              maxiter=500, m=4, stationary=False)\n",
    "\n",
    "        pred, ci = model.predict(n_periods=len(\n",
    "            df_test[\"moving_average_new_cases\"]), X=df_test[[\"moving_average_new_vaccinations\"]], alpha=0.05, return_conf_int=True)\n",
    "\n",
    "        rmse = math.sqrt(mean_squared_error(\n",
    "            df_test[\"moving_average_new_cases\"], pred))\n",
    "        # print('Test RMSE: %.3f' % rmse)\n",
    "        if rmse < min_rmse:\n",
    "            min_rmse = rmse\n",
    "            best_model = model\n",
    "            best_pred = pred\n",
    "            best_d = diff\n",
    "    return best_model, best_pred, best_d, min_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated: error_action (3620545507.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[105], line 42\u001b[0;36m\u001b[0m\n\u001b[0;31m    error_action='ignore',)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated: error_action\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "#interval technique\n",
    "BayesOffline = c.BayesOffline()\n",
    "media_changepoint = 0.0\n",
    "count_changepoint = 0.0\n",
    "min_changepoint = (999,\"error\")\n",
    "max_changepoint = (-1,\"error\")\n",
    "save_me = []\n",
    "tabella = pd.DataFrame(columns=['State','FirstSlope','SecondSlope','ThirdSlope','FourthSlope'])\n",
    "trend_negative = []\n",
    "trend_positive = []\n",
    "\n",
    "for code in iso_code_list:\n",
    "    # STEP 1: crea un df con solo data e valore per ogni stato\n",
    "    df_cases = pd.DataFrame(df_new_cases.loc[code]['moving_average_new_cases'].values, index = df_new_cases.loc[code]['moving_average_new_cases'].index, columns = ['moving_average_new_cases'])\n",
    "    df_vaccin = pd.DataFrame(df_vaccination.loc[code]['moving_average_new_vaccinations'].values, index = df_vaccination.loc[code]['moving_average_new_vaccinations'].index, columns = ['moving_average_new_vaccinations'])\n",
    "    \n",
    "    # STEP 2: mergia i due df in uno solo\n",
    "    merged_df = df_cases.merge(df_vaccin, on=['date'])\n",
    "    merged_df.to_csv(\"./merged_df.csv\")\n",
    "    \n",
    "    # STEP 3: split the data into train and test from split_date\n",
    "    split_date = date(2021, 7, 28)\n",
    "    merged_df_train = merged_df.loc[merged_df.index <= str(split_date)].copy()\n",
    "    merged_df_test = merged_df.loc[merged_df.index > str(split_date)].copy()\n",
    "    \n",
    "    best_model, best_pred, best_d, min_rmse = train_model(merged_df_train, merged_df_test)\n",
    "    \n",
    "    # STEP 4: crea un modello auto_ARIMA per predirre i new_cases considerando i vaccini fino 2 settimane prima dell'inizio delle olimpiadi\n",
    "    model = pm.auto_arima(merged_df_train['moving_average_new_cases'], X=merged_df_train[\"moving_average_new_vaccinations\"], start_p=0, start_q=0,\n",
    "                                test='adf',       # use adftest to find optimal 'd'\n",
    "                                max_p=3, max_q=3, # maximum p and q\n",
    "                                d=best_d,          # let model determine 'd'\n",
    "                                m=1,              # frequency of series\n",
    "                                error_action='ignore',\n",
    "                                suppress_warnings=True,\n",
    "                                random_state=42,\n",
    "                                maxiter=500,\n",
    "                                stationary=False,\n",
    "                                seasonal=True,\n",
    "                                trace=True,\n",
    "                                error_action='ignore',)\n",
    "    \n",
    "    pred, ci = newmodel.predict(n_periods=length, X=df_help[[\"moving_average_new_vaccinations\"]], alpha=0.05, return_conf_int=True)\n",
    "    print(\"------------------\")\n",
    "    print(pred)\n",
    "    print(\"------------------\")\n",
    "    \n",
    "    ARIMAModel = ARIMA(df_train, order=(1,1,1))\n",
    "    ARIMAModel_fit = ARIMAModel.fit()\n",
    "    ARIMAModel_fit.summary()\n",
    "    \n",
    "    #STEP 5: dividi il test set in 3 parti: 14 giorni prima, durante le olimpiadi e 14 giorni dopo\n",
    "    before_olympic = merged_df_test.loc[merged_df_test.index <= str(split_date + datetime.timedelta(days=14))].copy()\n",
    "    during_olympic = merged_df_test.loc[(merged_df_test.index > str(split_date + datetime.timedelta(days=14))) & (merged_df_test.index <= str(split_date + datetime.timedelta(days=21)))].copy()\n",
    "    after_olympic = merged_df_test.loc[merged_df_test.index > str(split_date + datetime.timedelta(days=21))].copy()\n",
    "    \n",
    "    #STEP 6: predici i new_cases per le 3 parti del test set\n",
    "    before_olympic_predicted = ARIMAModel_fit.predict(start = len(merged_df_train), end = len(merged_df_train)+13)\n",
    "    during_olympic_predicted = ARIMAModel_fit.predict(start = len(merged_df_train)+14, end = len(merged_df_train)+21)\n",
    "    after_olympic_predicted = ARIMAModel_fit.predict(start = len(merged_df_train)+22, end = len(merged_df_train)+35)\n",
    "    \n",
    "    #STEP 7: calcola la media dei new_cases predetti per le 3 parti del test set\n",
    "    before_olympic_mean_predicted = before_olympic_predicted.mean()\n",
    "    during_olympic_mean_predicted = during_olympic_predicted.mean()\n",
    "    after_olympic_mean_predicted = after_olympic_predicted.mean()\n",
    "    \n",
    "    #STEP 8: calcola la differenza tra la media dei new_cases predetti e la media dei new_cases reali per le 3 parti del test set\n",
    "    before_olympic_difference = before_olympic_mean_predicted - before_olympic['moving_average_new_cases'].mean()\n",
    "    during_olympic_difference = during_olympic_mean_predicted - during_olympic['moving_average_new_cases'].mean()\n",
    "    after_olympic_difference = after_olympic_mean_predicted - after_olympic['moving_average_new_cases'].mean()\n",
    "    \n",
    "    #STEP 9: calcola la percentuale di differenza tra la media dei new_cases predetti e la media dei new_cases reali per le 3 parti del test set\n",
    "    before_olympic_percentage_difference = (before_olympic_difference/before_olympic['moving_average_new_cases'].mean())*100\n",
    "    during_olympic_percentage_difference = (during_olympic_difference/during_olympic['moving_average_new_cases'].mean())*100\n",
    "    after_olympic_percentage_difference = (after_olympic_difference/after_olympic['moving_average_new_cases'].mean())*100\n",
    "    \n",
    "    #STEP 10: salva i risultati in un df\n",
    "    row = pd.DataFrame.from_dict({'State': code, 'FirstSlope': before_olympic_percentage_difference, 'SecondSlope': during_olympic_percentage_difference, 'ThirdSlope': after_olympic_percentage_difference}, orient='index').T\n",
    "    tabella = pd.concat([tabella, row], ignore_index=True)\n",
    "    \n",
    "    #STEP 11: plot the results\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(before_olympic.index, before_olympic['moving_average_new_cases'], label = 'Real new cases')\n",
    "    plt.plot(before_olympic.index, before_olympic_predicted, label = 'Predicted new cases')\n",
    "    plt.plot(during_olympic.index, during_olympic['moving_average_new_cases'], label = 'Real new cases')\n",
    "    plt.plot(during_olympic.index, during_olympic_predicted, label = 'Predicted new cases')\n",
    "    plt.plot(after_olympic.index, after_olympic['moving_average_new_cases'], label = 'Real new cases')\n",
    "    plt.plot(after_olympic.index, after_olympic_predicted, label = 'Predicted new cases')\n",
    "    plt.title(code + \" - \" + df_new_cases.loc[code]['Country'].unique()[0])\n",
    "    plt.axvline(x = difference.days-14, color = 'blue', label = '14 days before first game of olympic games')\n",
    "    plt.axvline(x = difference.days+7, color = 'orange', label = '7 days after first game of olympic games')\n",
    "    plt.axvline(x = difference.days+18, color = '#FF7D4D', label = '7 days after last game of olympic games')\n",
    "    plt.xlabel(\"Days since the 28th of July 2021\")\n",
    "    plt.ylabel(\"Current MA - Previous MA\")\n",
    "    plt.legend()\n",
    "    plt.axvspan(difference.days, difference.days+11, facecolor='#ffe206', alpha=0.5)\n",
    "    ymax = plt.ylim()[1]\n",
    "    # aggiungi un margine di 5% sopra il massimo valore per far spazio alle etichette\n",
    "    plt.ylim(ymax=ymax*1.20)\n",
    "    plt.text(difference.days-14, ymax, \"14 days before\\nfirst game of\\nolympic games\", rotation=0, color=\"white\", backgroundcolor=\"blue\")\n",
    "    plt.text(difference.days, ymax, \"Olympic \\nGames\", rotation=0, color=\"black\", backgroundcolor=\"yellow\")\n",
    "    plt.text(difference.days+7+1, ymax, \"7 days \\nafter first metch\", rotation=0, backgroundcolor=\"orange\")\n",
    "    plt.text(difference.days+18+1, ymax, \"7 days \\nafter last match\", rotation=0, backgroundcolor=\"#FF7D4D\")\n",
    "    #save the plot as a png file\n",
    "    plt.savefig(\"../pictures/\"+ code + \"_intervals\" +\".png\")\n",
    "    plt.show()\n",
    "\n",
    "'''    # Crea un plot con i punti di cambio colorati\n",
    "    plt.title(code + \" - \" + df_new_cases.loc[code]['Country'].unique()[0])\n",
    "    plt.axvline(x = difference.days-14, color = 'blue', label = '14 days before first game of olympic games')\n",
    "    plt.axvline(x = difference.days+7, color = 'orange', label = '7 days after first game of olympic games')\n",
    "    plt.axvline(x = difference.days+18, color = '#FF7D4D', label = '7 days after last game of olympic games')\n",
    "    plt.xlabel(\"Days since the 28th of July 2021\")\n",
    "    plt.ylabel(\"Current MA - Previous MA\")\n",
    "    #plt.legend()\n",
    "    plt.axvspan(difference.days, difference.days+11, facecolor='#ffe206', alpha=0.5)\n",
    "    ymax = plt.ylim()[1]\n",
    "    # aggiungi un margine di 5% sopra il massimo valore per far spazio alle etichette\n",
    "    plt.ylim(ymax=ymax*1.20)\n",
    "    plt.text(difference.days-14, ymax, \"14 days before\\nfirst game of\\nolympic games\", rotation=0, color=\"white\", backgroundcolor=\"blue\")\n",
    "    plt.text(difference.days, ymax, \"Olympic \\nGames\", rotation=0, color=\"black\", backgroundcolor=\"yellow\")\n",
    "    plt.text(difference.days+7+1, ymax, \"7 days \\nafter first metch\", rotation=0, backgroundcolor=\"orange\")\n",
    "    plt.text(difference.days+18+1, ymax, \"7 days \\nafter last match\", rotation=0, backgroundcolor=\"#FF7D4D\")\n",
    "    #save the plot as a png file\n",
    "    plt.savefig(\"../pictures/\"+ code + \"_intervals\" +\".png\")\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabella is the table for changepoints and tabella2 is the table for the intervals\n",
    "tabella.set_index(tabella['State'])\n",
    "tabella.to_csv(\"./tabella.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
