{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sdt.changepoint as c\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ARIMA libraries\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics import tsaplots\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pmdarima as pm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from the csv file\n",
    "df_new_cases = pd.read_csv('../data/WHO-COVID-19-global-data.csv')\n",
    "#df_vaccination = pd.read_csv('../data/owid-covid-data.csv')\n",
    "df_vaccination = pd.read_csv('../data/country_vaccinations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add moving average for new cases\n",
    "#df_vaccination['moving_average_new_vaccinations'] = df_vaccination.groupby('iso_code')['new_vaccinations'].transform(lambda x: x.rolling(window=7).mean()) # OWID\n",
    "df_vaccination['moving_average_new_vaccinations'] = df_vaccination.groupby('iso_code')['daily_vaccinations'].transform(lambda x: x.rolling(window=7).mean())\n",
    "\n",
    "# rimuovi tutte le righe che non hanno un valore o hanno un valore a \"0.0\" per moving_average_new_cases\n",
    "df_vaccination = df_vaccination.dropna(subset=['moving_average_new_vaccinations'])\n",
    "df_vaccination = df_vaccination[df_vaccination['moving_average_new_vaccinations'] != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add moving average for new cases\n",
    "df_new_cases['moving_average_new_cases'] = df_new_cases.groupby('Country_code')['New_cases'].transform(lambda x: x.rolling(window=7).mean())\n",
    "\n",
    "# rimuovi tutte le righe che non hanno un valore o hanno un valore a \"0.0\" per moving_average_new_cases\n",
    "df_new_cases = df_new_cases.dropna(subset=['moving_average_new_cases'])\n",
    "df_new_cases = df_new_cases[df_new_cases['moving_average_new_cases'] != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firter data from 2021-07-16 to 2021-08-15\n",
    "start_date = date(2021, 7, 1) \n",
    "og_start_date = date(2021, 7, 22)\n",
    "og_end_date = date(2021, 8, 8)\n",
    "end_date = date(2021, 8, 31)\n",
    "\n",
    "difference = og_start_date - start_date\n",
    "event_duration = og_end_date - og_start_date\n",
    "\n",
    "# filter data from 2021-07-16 to 2021-08-15\n",
    "df_new_cases = df_new_cases[(df_new_cases['Date_reported'] >= str(start_date)) & (df_new_cases['Date_reported'] <= str(end_date))]\n",
    "\n",
    "# filter df_vaccination from 2021-07-16 to 2021-08-15\n",
    "df_vaccination = df_vaccination[(df_vaccination['date'] >= str(start_date)) & (df_vaccination['date'] <= str(end_date))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter by iso_cod that not contain \"OWID\" prefix\n",
    "df_vaccination = df_vaccination[~df_vaccination['iso_code'].str.contains(\"OWID\")]\n",
    "\n",
    "# aggragate by iso_code and date and sum total_cases, total_deaths, population, total_vaccinations, new_cases, mind positive_rate, max positive_rate,KEEP LOCATION \n",
    "#df_vaccination = df_vaccination.groupby(['iso_code', 'date']).agg({'people_vaccinated':'sum', 'new_vaccinations': 'sum', 'location': 'max', 'moving_average_new_vaccinations': 'sum'})\n",
    "df_vaccination = df_vaccination.groupby(['iso_code', 'date']).agg({'total_vaccinations':'sum', 'daily_vaccinations': 'sum', 'country': 'max', 'moving_average_new_vaccinations': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggragate by iso_code and date and sum total_cases, total_deaths, population, total_vaccinations, new_cases, mind positive_rate, max positive_rate,KEEP LOCATION \n",
    "df_new_cases = df_new_cases.groupby(['Country_code', 'Date_reported']).agg({'Country': 'sum', 'WHO_region': 'sum', 'New_cases': 'sum', 'Cumulative_cases': 'sum', 'New_deaths': 'sum', 'Cumulative_deaths': 'sum', 'moving_average_new_cases': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggiungi alla riga attuale nella colonna iso_code il valore iso\n",
    "convert_ISO_3166_2_to_1 = {\n",
    "    'AF':'AFG',\n",
    "    'AX':'ALA',\n",
    "    'AL':'ALB',\n",
    "    'DZ':'DZA',\n",
    "    'AS':'ASM',\n",
    "    'AD':'AND',\n",
    "    'AO':'AGO',\n",
    "    'AI':'AIA',\n",
    "    'AQ':'ATA',\n",
    "    'AG':'ATG',\n",
    "    'AR':'ARG',\n",
    "    'AM':'ARM',\n",
    "    'AW':'ABW',\n",
    "    'AU':'AUS',\n",
    "    'AT':'AUT',\n",
    "    'AZ':'AZE',\n",
    "    'BS':'BHS',\n",
    "    'BH':'BHR',\n",
    "    'BD':'BGD',\n",
    "    'BB':'BRB',\n",
    "    'BY':'BLR',\n",
    "    'BE':'BEL',\n",
    "    'BZ':'BLZ',\n",
    "    'BJ':'BEN',\n",
    "    'BM':'BMU',\n",
    "    'BT':'BTN',\n",
    "    'BO':'BOL',\n",
    "    'BA':'BIH',\n",
    "    'BW':'BWA',\n",
    "    'BV':'BVT',\n",
    "    'BR':'BRA',\n",
    "    'IO':'IOT',\n",
    "    'BN':'BRN',\n",
    "    'BG':'BGR',\n",
    "    'BF':'BFA',\n",
    "    'BI':'BDI',\n",
    "    'KH':'KHM',\n",
    "    'CM':'CMR',\n",
    "    'CA':'CAN',\n",
    "    'CV':'CPV',\n",
    "    'KY':'CYM',\n",
    "    'CF':'CAF',\n",
    "    'TD':'TCD',\n",
    "    'CL':'CHL',\n",
    "    'CN':'CHN',\n",
    "    'CX':'CXR',\n",
    "    'CC':'CCK',\n",
    "    'CO':'COL',\n",
    "    'KM':'COM',\n",
    "    'CG':'COG',\n",
    "    'CD':'COD',\n",
    "    'CK':'COK',\n",
    "    'CR':'CRI',\n",
    "    'CI':'CIV',\n",
    "    'HR':'HRV',\n",
    "    'CU':'CUB',\n",
    "    'CY':'CYP',\n",
    "    'CZ':'CZE',\n",
    "    'DK':'DNK',\n",
    "    'DJ':'DJI',\n",
    "    'DM':'DMA',\n",
    "    'DO':'DOM',\n",
    "    'EC':'ECU',\n",
    "    'EG':'EGY',\n",
    "    'SV':'SLV',\n",
    "    'GQ':'GNQ',\n",
    "    'ER':'ERI',\n",
    "    'EE':'EST',\n",
    "    'ET':'ETH',\n",
    "    'FK':'FLK',\n",
    "    'FO':'FRO',\n",
    "    'FJ':'FJI',\n",
    "    'FI':'FIN',\n",
    "    'FR':'FRA',\n",
    "    'GF':'GUF',\n",
    "    'PF':'PYF',\n",
    "    'TF':'ATF',\n",
    "    'GA':'GAB',\n",
    "    'GM':'GMB',\n",
    "    'GE':'GEO',\n",
    "    'DE':'DEU',\n",
    "    'GH':'GHA',\n",
    "    'GI':'GIB',\n",
    "    'GR':'GRC',\n",
    "    'GL':'GRL',\n",
    "    'GD':'GRD',\n",
    "    'GP':'GLP',\n",
    "    'GU':'GUM',\n",
    "    'GT':'GTM',\n",
    "    'GG':'GGY',\n",
    "    'GN':'GIN',\n",
    "    'GW':'GNB',\n",
    "    'GY':'GUY',\n",
    "    'HT':'HTI',\n",
    "    'HM':'HMD',\n",
    "    'VA':'VAT',\n",
    "    'HN':'HND',\n",
    "    'HK':'HKG',\n",
    "    'HU':'HUN',\n",
    "    'IS':'ISL',\n",
    "    'IN':'IND',\n",
    "    'ID':'IDN',\n",
    "    'IR':'IRN',\n",
    "    'IQ':'IRQ',\n",
    "    'IE':'IRL',\n",
    "    'IM':'IMN',\n",
    "    'IL':'ISR',\n",
    "    'IT':'ITA',\n",
    "    'JM':'JAM',\n",
    "    'JP':'JPN',\n",
    "    'JE':'JEY',\n",
    "    'JO':'JOR',\n",
    "    'KZ':'KAZ',\n",
    "    'KE':'KEN',\n",
    "    'KI':'KIR',\n",
    "    'KP':'PRK',\n",
    "    'KR':'KOR',\n",
    "    'KW':'KWT',\n",
    "    'KG':'KGZ',\n",
    "    'LA':'LAO',\n",
    "    'LV':'LVA',\n",
    "    'LB':'LBN',\n",
    "    'LS':'LSO',\n",
    "    'LR':'LBR',\n",
    "    'LY':'LBY',\n",
    "    'LI':'LIE',\n",
    "    'LT':'LTU',\n",
    "    'LU':'LUX',\n",
    "    'MO':'MAC',\n",
    "    'MK':'MKD',\n",
    "    'MG':'MDG',\n",
    "    'MW':'MWI',\n",
    "    'MY':'MYS',\n",
    "    'MV':'MDV',\n",
    "    'ML':'MLI',\n",
    "    'MT':'MLT',\n",
    "    'MH':'MHL',\n",
    "    'MQ':'MTQ',\n",
    "    'MR':'MRT',\n",
    "    'MU':'MUS',\n",
    "    'YT':'MYT',\n",
    "    'MX':'MEX',\n",
    "    'FM':'FSM',\n",
    "    'MD':'MDA',\n",
    "    'MC':'MCO',\n",
    "    'MN':'MNG',\n",
    "    'ME':'MNE',\n",
    "    'MS':'MSR',\n",
    "    'MA':'MAR',\n",
    "    'MZ':'MOZ',\n",
    "    'MM':'MMR',\n",
    "    'NA':'NAM',\n",
    "    'NR':'NRU',\n",
    "    'NP':'NPL',\n",
    "    'NL':'NLD',\n",
    "    'AN':'ANT',\n",
    "    'NC':'NCL',\n",
    "    'NZ':'NZL',\n",
    "    'NI':'NIC',\n",
    "    'NE':'NER',\n",
    "    'NG':'NGA',\n",
    "    'NU':'NIU',\n",
    "    'NF':'NFK',\n",
    "    'MP':'MNP',\n",
    "    'NO':'NOR',\n",
    "    'OM':'OMN',\n",
    "    'PK':'PAK',\n",
    "    'PW':'PLW',\n",
    "    'PS':'PSE',\n",
    "    'PA':'PAN',\n",
    "    'PG':'PNG',\n",
    "    'PY':'PRY',\n",
    "    'PE':'PER',\n",
    "    'PH':'PHL',\n",
    "    'PN':'PCN',\n",
    "    'PL':'POL',\n",
    "    'PT':'PRT',\n",
    "    'PR':'PRI',\n",
    "    'QA':'QAT',\n",
    "    'RE':'REU',\n",
    "    'RO':'ROU',\n",
    "    'RU':'RUS',\n",
    "    'RW':'RWA',\n",
    "    'BL':'BLM',\n",
    "    'SH':'SHN',\n",
    "    'KN':'KNA',\n",
    "    'LC':'LCA',\n",
    "    'MF':'MAF',\n",
    "    'PM':'SPM',\n",
    "    'VC':'VCT',\n",
    "    'WS':'WSM',\n",
    "    'SM':'SMR',\n",
    "    'ST':'STP',\n",
    "    'SA':'SAU',\n",
    "    'SN':'SEN',\n",
    "    'RS':'SRB',\n",
    "    'SC':'SYC',\n",
    "    'SL':'SLE',\n",
    "    'SG':'SGP',\n",
    "    'SK':'SVK',\n",
    "    'SI':'SVN',\n",
    "    'SB':'SLB',\n",
    "    'SO':'SOM',\n",
    "    'ZA':'ZAF',\n",
    "    'GS':'SGS',\n",
    "    'ES':'ESP',\n",
    "    'LK':'LKA',\n",
    "    'SD':'SDN',\n",
    "    'SR':'SUR',\n",
    "    'SJ':'SJM',\n",
    "    'SZ':'SWZ',\n",
    "    'SE':'SWE',\n",
    "    'CH':'CHE',\n",
    "    'SY':'SYR',\n",
    "    'TW':'TWN',\n",
    "    'TJ':'TJK',\n",
    "    'TZ':'TZA',\n",
    "    'TH':'THA',\n",
    "    'TL':'TLS',\n",
    "    'TG':'TGO',\n",
    "    'TK':'TKL',\n",
    "    'TO':'TON',\n",
    "    'TT':'TTO',\n",
    "    'TN':'TUN',\n",
    "    'TR':'TUR',\n",
    "    'TM':'TKM',\n",
    "    'TC':'TCA',\n",
    "    'TV':'TUV',\n",
    "    'UG':'UGA',\n",
    "    'UA':'UKR',\n",
    "    'AE':'ARE',\n",
    "    'GB':'GBR',\n",
    "    'US':'USA',\n",
    "    'UM':'UMI',\n",
    "    'UY':'URY',\n",
    "    'UZ':'UZB',\n",
    "    'VU':'VUT',\n",
    "    'VE':'VEN',\n",
    "    'VN':'VNM',\n",
    "    'VG':'VGB',\n",
    "    'VI':'VIR',\n",
    "    'WF':'WLF',\n",
    "    'EH':'ESH',\n",
    "    'YE':'YEM',\n",
    "    'ZM':'ZMB',\n",
    "    'ZW':'ZWE'\n",
    "}\n",
    "\n",
    "for code in df_new_cases.index.get_level_values('Country_code').unique():\n",
    "    if code not in country_code_to_iso:\n",
    "        print(code , \"NOT FOUND\")\n",
    "        continue\n",
    "    iso = country_code_to_iso[code]\n",
    "    df_new_cases.loc[(df_new_cases.index.get_level_values('Country_code') == code), 'iso_code'] = iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe in csv file\n",
    "df_new_cases.to_csv('./dataframe.csv')\n",
    "df_vaccination.to_csv('./vaccinations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for iso_code in df_vaccination.index.get_level_values(\\'iso_code\\').unique():\\n    plt.plot(df_vaccination.loc[iso_code][\\'moving_average_new_vaccinations\\'], label=\\'vaccinations\\')\\n    plt.title(df_vaccination.loc[iso_code][\\'country\\'].unique()[0])\\n    plt.ylabel(\"new vaccinations\")\\n    plt.xlabel(\"Date\")\\n    plt.xticks(rotation=90)\\n    plt.show()'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for iso_code in df_vaccination.index.get_level_values('iso_code').unique():\n",
    "    plt.plot(df_vaccination.loc[iso_code]['moving_average_new_vaccinations'], label='vaccinations')\n",
    "    plt.title(df_vaccination.loc[iso_code]['country'].unique()[0])\n",
    "    plt.ylabel(\"new vaccinations\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# crea una lista di tutti gli iso_code presenti in df_new_cases\n",
    "iso_code_list = df_new_cases['iso_code'].unique().tolist()\n",
    "#print(len(iso_code_list))\n",
    "#print(df_new_cases.index.levels[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "#interval technique\n",
    "BayesOffline = c.BayesOffline()\n",
    "media_changepoint = 0.0\n",
    "count_changepoint = 0.0\n",
    "min_changepoint = (999,\"error\")\n",
    "max_changepoint = (-1,\"error\")\n",
    "save_me = []\n",
    "tabella = pd.DataFrame(columns=['State','FirstSlope','SecondSlope','ThirdSlope','FourthSlope'])\n",
    "trend_negative = []\n",
    "trend_positive = []\n",
    "\n",
    "for code in all_iso_codes:\n",
    "    # Out is a list of possible changepoint \"indices\"\n",
    "    values = df_new_cases.loc[code]['moving_average_new_cases'].values\n",
    "    \n",
    "    #crea un df \n",
    "    df_cases = pd.DataFrame(values, index = df_new_cases.loc[code]['moving_average_new_cases'].index, columns = ['new_cases'])\n",
    "    df_vaccin = pd.DataFrame(df_vaccination.loc[code]['moving_average_new_vaccinations'].values, index = df_vaccination.loc[code]['moving_average_new_vaccinations'].index, columns = ['new_vaccinations'])\n",
    "    \n",
    "    merged_df = df_cases.merge(df_vaccination, on=['iso_code', 'date'])\n",
    "    print(merged_df)\n",
    "    print(merged_df.index)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # crea un df con i valori di new_cases e indice le righe con le date\n",
    "    df = pd.DataFrame(values, index = df_vaccination.loc[code]['moving_average_new_vaccinations'].index, columns = ['new_cases'])\n",
    "    print(df)\n",
    "    print(df.index)\n",
    "    \n",
    "    #splitta il df in due dataframe di training e di test con split date\n",
    "    df_train = df.loc[df.index <= str(split_date)].copy()\n",
    "    df_test = df.loc[df.index > str(split_date)].copy()\n",
    "    \n",
    "    \n",
    "    # crea un modello ARIMA per predirre i new_cases considerando i vaccini fino 2 settimane prima dell'inizio delle olimpiadi\n",
    "    ARIMAModel = ARIMA(df_train, order=(1,1,1))\n",
    "    ARIMAModel_fit = ARIMAModel.fit()\n",
    "    ARIMAModel_fit.summary()\n",
    "    # predice i new_cases per le due settimane delle olimpiadi\n",
    "    ARIMAModel_fit.predict(start = len(df_train), end = len(df_train)+13)\n",
    "    # calcola la media dei new_cases predetti\n",
    "    mean_predicted = ARIMAModel_fit.predict(start = len(df_train), end = len(df_train)+13).mean()\n",
    "    # calcola la media dei new_cases reali\n",
    "    mean_real = df_test.mean()\n",
    "    # calcola la differenza tra la media dei new_cases predetti e la media dei new_cases reali\n",
    "    difference = mean_predicted - mean_real\n",
    "    # calcola la percentuale di differenza tra la media dei new_cases predetti e la media dei new_cases reali\n",
    "    percentage_difference = (difference/mean_real)*100\n",
    "    print(\"The mean of the predicted new cases is: \" + str(mean_predicted))\n",
    "    \n",
    "    # plot the predicted values\n",
    "    plt.plot(ARIMAModel_fit.predict(start = len(df_train), end = len(df_train)+13), color = 'red', label = 'Predicted new cases')\n",
    "    # plot the real values\n",
    "    plt.plot(df_test, color = 'blue', label = 'Real new cases')\n",
    "    plt.title(code + \" - \" + df_new_cases.loc[code]['Country'].unique()[0])\n",
    "    plt.xlabel(\"Days since the 28th of July 2021\")\n",
    "    plt.ylabel(\"Current MA - Previous MA\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    '''df2 = df_new_cases.loc[code]['moving_average_new_cases']\n",
    "    # Questa riga estrae i valori della colonna \"Data\" del dataframe df dalla prima data del dataframe alla data del lockdown.\n",
    "    values_before = df2.iloc[:difference.days+1].values\n",
    "    # Questa riga estrae i valori della colonna \"Data\" del dataframe df dalla data del lockdown fino alla settimana successiva 4.\n",
    "    values_oneWeek = df2.iloc[difference.days+1:difference.days+8].values\n",
    "    # Questa riga estrae i valori della colonna \"Data\" del dataframe df dalla data del lockdown fino alla settimana successiva 5.\n",
    "    values_twoWeek = df2.iloc[difference.days+8:difference.days+15].values\n",
    "    # Questa riga estrae i valori della colonna \"Data\" del dataframe df dalla data del lockdown fino alla settimana successiva 6.\n",
    "    values_after = df2.iloc[difference.days+15:].values\n",
    "\n",
    "\n",
    "    z1 = np.polyfit(range(0,len(values_before)), values_before, 1)\n",
    "    p1 = np.poly1d(z1)\n",
    "    z2 = np.polyfit(range(len(values_before),len(values_before)+len(values_oneWeek)), values_oneWeek, 1)\n",
    "    p2 = np.poly1d(z2)\n",
    "    z3 = np.polyfit(range(len(values_before)+len(values_oneWeek),len(values_before)+len(values_oneWeek)+len(values_twoWeek)), values_twoWeek, 1)\n",
    "    p3 = np.poly1d(z3)\n",
    "    z4 = np.polyfit(range(len(values_before)+len(values_oneWeek)+len(values_twoWeek),len(values_before)+len(values_oneWeek)+len(values_twoWeek)+len(values_after)), values_after, 1)\n",
    "    p4 = np.poly1d(z4)\n",
    "    \n",
    "    entry = pd.DataFrame.from_dict({\"State\": code,'FirstSlope': [z1[0]],'SecondSlope': [z2[0]],'ThirdSlope': [z3[0]],'FourthSlope': [z4[0]]})\n",
    "    tabella = pd.concat([tabella2, entry], ignore_index=True)\n",
    "\n",
    "    array1 = np.arange(0,len(values_before))\n",
    "    array2 = np.arange(len(values_before),len(values_before)+len(values_oneWeek))\n",
    "    array2 = np.insert(array2, 0, array1[-1])\n",
    "    array3 = np.arange(len(values_before)+len(values_oneWeek),len(values_before)+len(values_oneWeek)+len(values_twoWeek))\n",
    "    array3 = np.insert(array3, 0, array2[-1])\n",
    "    array4 = np.arange(len(values_before)+len(values_oneWeek)+len(values_twoWeek),len(values_before)+len(values_oneWeek)+len(values_twoWeek)+len(values_after))\n",
    "    array4 = np.insert(array4, 0, array3[-1])\n",
    "    lw = 2\n",
    "    \n",
    "\n",
    "    plt.plot(array1, p1(range(0,len(values_before))), color=\"#0B1F65\", linewidth=lw, linestyle=\"dashdot\")\n",
    "    plt.plot(array2, p2(range(len(values_before)-1,len(values_before)+len(values_oneWeek))), color=\"#116530\", linewidth=lw, linestyle=\"dashdot\")\n",
    "    plt.plot(array3, p3(range(len(values_before)+len(values_oneWeek)-1,len(values_before)+len(values_oneWeek)+len(values_twoWeek))), color=\"#D7A449\", linewidth=lw, linestyle=\"dashdot\")\n",
    "    plt.plot(array4, p4(range(len(values_before)+len(values_oneWeek)+len(values_twoWeek)-1,len(values_before)+len(values_oneWeek)+len(values_twoWeek)+len(values_after))), color=\"#DB3F29\", linewidth=lw, linestyle=\"dashdot\")\n",
    "    '''\n",
    "    # Crea un plot con i punti di cambio colorati\n",
    "    plt.title(code + \" - \" + df_new_cases.loc[code]['Country'].unique()[0])\n",
    "    plt.axvline(x = difference.days-14, color = 'blue', label = '14 days before first game of olympic games')\n",
    "    plt.axvline(x = difference.days+7, color = 'orange', label = '7 days after first game of olympic games')\n",
    "    plt.axvline(x = difference.days+18, color = '#FF7D4D', label = '7 days after last game of olympic games')\n",
    "    plt.xlabel(\"Days since the 28th of July 2021\")\n",
    "    plt.ylabel(\"Current MA - Previous MA\")\n",
    "    #plt.legend()\n",
    "    plt.axvspan(difference.days, difference.days+11, facecolor='#ffe206', alpha=0.5)\n",
    "    ymax = plt.ylim()[1]\n",
    "    # aggiungi un margine di 5% sopra il massimo valore per far spazio alle etichette\n",
    "    plt.ylim(ymax=ymax*1.20)\n",
    "    plt.text(difference.days-14, ymax, \"14 days before\\nfirst game of\\nolympic games\", rotation=0, color=\"white\", backgroundcolor=\"blue\")\n",
    "    plt.text(difference.days, ymax, \"Olympic \\nGames\", rotation=0, color=\"black\", backgroundcolor=\"yellow\")\n",
    "    plt.text(difference.days+7+1, ymax, \"7 days \\nafter first metch\", rotation=0, backgroundcolor=\"orange\")\n",
    "    plt.text(difference.days+18+1, ymax, \"7 days \\nafter last match\", rotation=0, backgroundcolor=\"#FF7D4D\")\n",
    "    #save the plot as a png file\n",
    "    plt.savefig(\"../pictures/\"+ code + \"_intervals\" +\".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabella is the table for changepoints and tabella2 is the table for the intervals\n",
    "tabella.set_index(tabella['State'])\n",
    "tabella.to_csv(\"./tabella.csv\", index=False)\n",
    "\n",
    "tabella2.set_index(tabella2['State'])\n",
    "tabella2.to_csv(\"./tabella2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
